{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erictong0/FrederickLab2023/blob/main/Subtraction/INADEQUATE/230714_GLY_subtraction_2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bio --upgrade"
      ],
      "metadata": {
        "id": "gAI2sf0iqKDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from posixpath import join\n",
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as pltticker\n",
        "import scipy as sp\n",
        "import csv\n",
        "import re\n",
        "import traceback\n",
        "from matplotlib import colors\n",
        "import matplotlib.cm as cm\n",
        "from statistics import mean\n",
        "from Bio.Data.IUPACData import protein_letters_1to3 as one2three\n",
        "from numpy import savetxt\n",
        "from seaborn.widgets import color_palette"
      ],
      "metadata": {
        "id": "218_M7ULqJAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQT8Emg03yKX"
      },
      "outputs": [],
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa):\n",
        "  aa1 = aa\n",
        "\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 4) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  #j = y ###Might change in future?\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "\n",
        "\n",
        "\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  'G':[[40,50],[212,227],[167,181],[ 98,119]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0][0],x_lims[0][1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0][0]+hw,x_lims[0][1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  # calculate counts for bins #\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "  H = H1\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 4 # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = -.325\n",
        "  adjDistY = 1.5\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0][0] - adjDistX, x_lims[0][1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0][0], x_lims[0][1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2 ,y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "  h = Z\n",
        "  c=[]\n",
        "  d =[]\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c=[]\n",
        "  d =[]\n",
        "  h_exp = H_exp\n",
        "  np.set_printoptions(threshold=np.inf)\n",
        "  #####################################################################\n",
        "  H_exp = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "  H_max = max([max(array) for array in H])\n",
        "  for i in range(len(H_exp)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp[i-1]) * H_max / H_exp_max\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp=np.array(d)\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "  h = np.subtract(H_exp,H)\n",
        "  savetxt('urea - GLY',h,delimiter=',')\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "\n",
        "  #######################################\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "  #######################################\n",
        "\n",
        "  subplot_counter = 0\n",
        "        # draw the subplot #\n",
        "  fig  = plt.figure(figsize=(15,10))\n",
        "\n",
        "  ax1 = fig.add_subplot(231, projection = '3d')\n",
        "  ax2 = fig.add_subplot(232, projection = '3d')\n",
        "  ax3 = fig.add_subplot(233, projection = '3d')\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  HS = [H_exp, H, np.subtract(H_exp,H)]\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  tempZ = np.array(HS).flatten().flatten()\n",
        "  max_height = np.max(tempZ)   # get range of colorbars so we can normalize\n",
        "  min_height = np.min(tempZ)\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cmap = cm.RdBu # Get desired colormap - you can change this!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    axs[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    axs[i].set_xlim(x_lims[0][0],aa_spec_ranges[aa1][0][1])\n",
        "    axs[i].set_ylim(y_lims[0],y_lims[1])\n",
        "    axs[i].set_zlim(0, .003)\n",
        "    axs[i].zaxis.set_visible(False)\n",
        "    #axs[i].grid(False)\n",
        "    axs[i].view_init(elev=30, azim=135)\n",
        "    axs[i].axis(\"off\")\n",
        "\n",
        "  ax1 = fig.add_subplot(234)\n",
        "  ax2 = fig.add_subplot(235)\n",
        "  ax3 = fig.add_subplot(236)\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  a = axs[0].contour(x_edges[:-1], y_edges[:-1], H_exp, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  b = axs[1].contour(x_edges[:-1], y_edges[:-1], H, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H) ###Controls the contour lines\n",
        "\n",
        "  c = axs[2].contour(x_edges[:-1], y_edges[:-1], h, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  for n in range(3):\n",
        "    axs[n].set_aspect('equal')\n",
        "    #axs[n].set_xlim(x_lims[0][0],aa_spec_ranges[aa1][0][1])\n",
        "    #axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    axs[n].set_xlim(40, 50)\n",
        "    axs[n].set_ylim(210, 225)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "\n",
        "\n",
        "  #cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  #plt.savefig(\"230714_GLY_Subtraction.svg\", format='svg')\n",
        "  plt.savefig(\"230714_GLY_Subtraction_3d.png\", format='png', dpi = 300)\n",
        "\n",
        "inputs = \"G_10K.out,230703_GLY_INADEQUATE_8M_Urea.txt,out,G\".split(\",\")\n",
        "PDB_file = inputs[0]\n",
        "exp_file = inputs[1]\n",
        "output_file_path = inputs[2]\n",
        "aa = inputs[3]\n",
        "main(PDB_file, exp_file, output_file_path, aa)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For moving average comparisons"
      ],
      "metadata": {
        "id": "OsRc4O8xsZal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa):\n",
        "  aa1 = aa\n",
        "\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 4) ###Change if not GLY\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  'A':[[44,61],[11,28],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w]\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0][0],x_lims[0][1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0][0]+hw,x_lims[0][1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  # calculate counts for bins #\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "  H = H1\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 3  # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 1.5\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0][0] - adjDistX, x_lims[0][1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0][0], x_lims[0][1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2 ,y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "  h = Z\n",
        "  c=[]\n",
        "  d =[]\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c=[]\n",
        "  d =[]\n",
        "  h_exp = H_exp\n",
        "  np.set_printoptions(threshold=np.inf)\n",
        "  #####################################################################\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp = sp.ndimage.uniform_filter(H_exp, size=6, mode='constant')\n",
        "  H_exp1 = sp.ndimage.uniform_filter(H_exp, size=8, mode='constant')\n",
        "  H_exp2 = sp.ndimage.uniform_filter(H_exp, size=10, mode='constant')\n",
        "  H_Arr = [H_exp, H_exp1, H_exp2]\n",
        "  for i in range(len(H_Arr)):\n",
        "    c = []\n",
        "    d = []\n",
        "    H_exp_max = max([max(array) for array in H_Arr[i]])\n",
        "    H_max = max([max(array) for array in H])\n",
        "    for j in range(len(H_exp)):\n",
        "      #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "      c = (H_exp[j-1]) * H_max / H_exp_max\n",
        "      #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "      d.append(c)\n",
        "    H_Arr[i]=np.array(d)\n",
        "  #####################################################################\n",
        "  H_exp = H_Arr[0]\n",
        "  H_exp1 = H_Arr[1]\n",
        "  H_exp2 = H_Arr[2]\n",
        "\n",
        "\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "  h = np.subtract(H_exp,H)\n",
        "  h1 = np.subtract(H_exp1,H)\n",
        "  h2 = np.subtract(H_exp2,H)\n",
        "\n",
        "  savetxt('urea - GLY',h,delimiter=',')\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "\n",
        "  #######################################\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "  #######################################\n",
        "\n",
        "  subplot_counter = 0\n",
        "        # draw the subplot #\n",
        "  fig = plt.figure(figsize = (16, 8))\n",
        "  ax1 = fig.add_subplot(231, projection='3d')\n",
        "  ax2 = fig.add_subplot(232, projection = '3d')\n",
        "  ax3 = fig.add_subplot(233, projection = '3d')\n",
        "  ax4 = fig.add_subplot(234, projection='3d')\n",
        "  ax5 = fig.add_subplot(235, projection = '3d')\n",
        "  ax6 = fig.add_subplot(236, projection = '3d')\n",
        "  AXS = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
        "  HS = [H_exp, H_exp1, H_exp2, h, h1, h2]\n",
        "\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    AXS[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    AXS[i].view_init(elev=80, azim=180)\n",
        "\n",
        "\n",
        "inputs = \"G_10K.out,230703_GLY_INADEQUATE_8M_Urea.txt,out,G\".split(\",\")\n",
        "PDB_file = inputs[0]\n",
        "exp_file = inputs[1]\n",
        "output_file_path = inputs[2]\n",
        "aa = inputs[3]\n",
        "main(PDB_file, exp_file, output_file_path, aa)\n",
        "plt.savefig(\"230703_GLY_Urea_Average_Differences.png\", format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dI-aBaDTsXWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For comparison of fwhm"
      ],
      "metadata": {
        "id": "n73KCamDsOHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa):\n",
        "  aa1 = aa\n",
        "\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 4) ###Change if not GLY\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  'A':[[44,61],[11,28],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w]\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0][0],x_lims[0][1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0][0]+hw,x_lims[0][1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  # calculate counts for bins #\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "  H = H1\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 1.5  # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 1.5\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0][0] - adjDistX, x_lims[0][1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0][0], x_lims[0][1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2 ,y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "  h = Z\n",
        "  c=[]\n",
        "  d =[]\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c=[]\n",
        "  d =[]\n",
        "  h_exp = H_exp\n",
        "  np.set_printoptions(threshold=np.inf)\n",
        "  #####################################################################\n",
        "  #H_exp = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "  H_max = max([max(array) for array in H])\n",
        "  for i in range(len(H_exp)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp[i-1]) * H_max / H_exp_max\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp=np.array(d)\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "  h = np.subtract(H_exp,H)\n",
        "  savetxt('urea - GLY',h,delimiter=',')\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "\n",
        "  #######################################\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "  #######################################\n",
        "\n",
        "  subplot_counter = 0\n",
        "        # draw the subplot #\n",
        "  fig = plt.figure(figsize = (12, 3))\n",
        "  ax1 = fig.add_subplot(131, projection='3d')\n",
        "  ax2 = fig.add_subplot(132, projection = '3d')\n",
        "  ax3 = fig.add_subplot(133, projection = '3d')\n",
        "  AXS = [ax1, ax2, ax3]\n",
        "  HS = [H_exp, H, h]\n",
        "\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(3):\n",
        "\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    AXS[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "\n",
        "\n",
        "inputs = \"G_10K.out,230703_GLY_INADEQUATE_8M_Urea.txt,out,G\".split(\",\")\n",
        "PDB_file = inputs[0]\n",
        "exp_file = inputs[1]\n",
        "output_file_path = inputs[2]\n",
        "aa = inputs[3]\n",
        "main(PDB_file, exp_file, output_file_path, aa)\n",
        "plt.savefig(\"230703_GLY_Urea_15FWHM_y15.png\", format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iyr82jexWz7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRhH001k6G1X"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig_grid_shape=(1,3) # modify for different grid arrangement of subplots\n",
        "fig, axs = plt.subplots(fig_grid_shape[0],fig_grid_shape[1], figsize=(10,10), tight_layout=True)\n",
        "\n",
        "print(\"Enter the file path, subplot number, and amino acid, separated by commas, or \\'Z\\' to quit: \")\n",
        "quit = False\n",
        "while not quit:\n",
        "  inputs = input()\n",
        "  if inputs.upper() == 'Z':\n",
        "    quit = True\n",
        "  else:\n",
        "    inputs = inputs.split(',')\n",
        "    PDB_file = inputs[0]\n",
        "    exp_file = inputs[1]\n",
        "    output_file_path = inputs[2]\n",
        "    aa = inputs[3]\n",
        "    main(PDB_file, exp_file, output_file_path, aa)\n",
        "    plt.show()\n",
        "    print(\"Enter the file path for AA, file path for experimental data, subplot number, and amino acid, separated by commas, or \\'Z\\' to quit: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1HF_Doc_V8h"
      },
      "outputs": [],
      "source": [
        "aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  'A':[[11,28],[55,89],[44,61],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                #  'G':[[36,53],[na,na],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "             #     'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "aa1 = 'S'\n",
        "fig_grid_shape=(2,3) # modify for different grid arrangement of subplots\n",
        "fig, axs = plt.subplots(fig_grid_shape[0],fig_grid_shape[1], figsize=(10,10), tight_layout=True)\n",
        "bin_width=0.25\n",
        "mtick_spacing=5\n",
        "x_lims = np.array(aa_spec_ranges[aa1])\n",
        "y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "x_edges = np.arange(x_lims[0][0],x_lims[2][1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "hw=bin_width/2\n",
        "center_bins_x=np.arange(x_lims[0][0]+hw,x_lims[2][1]+hw,bin_width)\n",
        "center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "sf=np.genfromtxt('urea', delimiter=',')\n",
        "ff=np.genfromtxt('no urea 2', delimiter=',')\n",
        "\n",
        "m=0\n",
        "n=0\n",
        "h=np.subtract(ff,sf)\n",
        "max_cont = np.max(h)\n",
        "ensemble_size = len(h)\n",
        "#factor size of 1.15\n",
        "#13steps\n",
        "min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "print(max_cont,min_cont)\n",
        "step = []\n",
        "for i in range(13):\n",
        "  x = 1.15**i\n",
        "  step.append(x)\n",
        "steps = sum(step)\n",
        "step_cont = max_cont/steps\n",
        "array = np.zeros(13)\n",
        "\n",
        "for i in range(13):\n",
        "  array[i] = ((1.15 ** i) * (step_cont)) + array[i-1]\n",
        "print(array)\n",
        "levels = array\n",
        "c = axs[m][n].contour(x_edges[:-1], y_edges[:-1], h, levels = levels, cmap='copper',linewidths=0.5)\n",
        "\n",
        "axs[m][n].set_aspect('equal')\n",
        "axs[m][n].set_xlim(x_lims[0][0],aa_spec_ranges[aa1][2][1])\n",
        "axs[m][n].set_ylim(y_lims[0],y_lims[1])\n",
        "axs[m][n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "axs[m][n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "axs[m][n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "axs[m][n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "axs[m][n].set_xlabel('ppm', labelpad=1.0)\n",
        "axs[m][n].set_ylabel('ppm', labelpad=1.0)\n",
        "axs[m][n].invert_xaxis()\n",
        "axs[m][n].invert_yaxis()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "n73KCamDsOHW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}