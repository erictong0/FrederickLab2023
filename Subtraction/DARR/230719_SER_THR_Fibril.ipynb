{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erictong0/FrederickLab2023/blob/main/Subtraction/DARR/230719_SER_THR_Fibril.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAI2sf0iqKDp"
      },
      "outputs": [],
      "source": [
        "!pip install bio --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "218_M7ULqJAb"
      },
      "outputs": [],
      "source": [
        "from posixpath import join\n",
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as pltticker\n",
        "import scipy as sp\n",
        "import csv\n",
        "import re\n",
        "import traceback\n",
        "from matplotlib import colors\n",
        "import matplotlib.cm as cm\n",
        "from statistics import mean\n",
        "from Bio.Data.IUPACData import protein_letters_1to3 as one2three\n",
        "from numpy import savetxt\n",
        "from seaborn.widgets import color_palette"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aaNameList = [\"ALA\", \"SER\", \"THR\"]\n",
        "\n",
        "#aaLetterList = [\"A\", \"S\", \"T\"]\n",
        "\n",
        "\n",
        "aaNameList = [\"SER\", \"THR\"]\n",
        "\n",
        "aaLetterList = [\"S\", \"T\"]"
      ],
      "metadata": {
        "id": "NR7l57OrHowA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3x3 grid: exp, 1.5 fwhm, 3 fwhm. 3d or contour"
      ],
      "metadata": {
        "id": "vs2ZxfFDbMDM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1HF_Doc_V8h"
      },
      "outputs": [],
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa, colNum):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 3) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  #j = y ###Might change in future?\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca   inadequate   Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  #'A':[[44,61],[55,89],[11,28],[170,184],[112,133]],\n",
        "                  # swapped Ca and Cb for A\n",
        "                   'A':[[11,28],[67,77],[48,58],[112,133]],\n",
        "                  #'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'S':[[56,66],[118,128],[55,72],[167,181],[104,125]],\n",
        "                  #'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'T':[[57,67],[128,138],[60,77],[168,182],[102,123]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, j, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "\n",
        "  ###changes for combining ca and cb###\n",
        "  #make x lim minimum to be aa_spec_ranges[aa1][0][0] and max is aa_spec_ranges[aa1][2][1]\n",
        "  x_lims = np.array([aa_spec_ranges[aa1][0][0],aa_spec_ranges[aa1][2][1]])\n",
        "  print(x_lims)\n",
        "  x_lims[0] += -5\n",
        "  x_lims[1] += 5\n",
        "\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1]) ####changed\n",
        "  y_lims[0] += -5\n",
        "  y_lims[1] += 5\n",
        "\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  #we'll just create a new histogram for cb data\n",
        "  # calculate counts for bins #\n",
        "  print(j)\n",
        "  print(x)\n",
        "\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "  H2, npxedges, npyedges = np.histogram2d(j, y,\n",
        "                                          bins=(y_edges,x_edges))\n",
        "  H = H1 #add together arrays later so memory isn't wasted on the gaussian\n",
        "  #create new array of H1 and H2 but in 1 dimension\n",
        "\n",
        "  #print(H)\n",
        "\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 1.5  # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H1, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "  Y = gaussian2d(npxedges[:-1], npyedges[:-1], H2, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "\n",
        "\n",
        "  h = np.sum((Z, Y), axis=0)\n",
        "\n",
        "  c=[]\n",
        "  d = []\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c = []\n",
        "  d = []\n",
        "\n",
        "  #H2 = np.flipud(np.fliplr(H2))\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 4\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0] - adjDistX, x_lims[1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0], x_lims[1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2, y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "\n",
        "  h_exp = H_exp\n",
        "  np.set_printoptions(threshold=np.inf)\n",
        "  #####################################################################\n",
        "  #H_exp = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "  H_max = max([max(array) for array in H])\n",
        "  for i in range(len(H_exp)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp[i-1]) * H_max / H_exp_max\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp=np.array(d)\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "  H2 = np.subtract(H_exp,H)\n",
        "  savetxt(f'urea - {aaName}',h,delimiter=',')\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "\n",
        "\n",
        "        # draw the subplot #\n",
        "  \"\"\"\n",
        "  ax1 = fig.add_subplot(int(f\"32{1+colNum}\"), projection = '3d')\n",
        "  ax2 = fig.add_subplot(int(f\"32{3+colNum}\"), projection = '3d')\n",
        "  ax3 = fig.add_subplot(int(f\"32{5+colNum}\"), projection = '3d')\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  HS = [H_exp, H, H2]\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "    axs[i].set_zlim(0, .0025)\n",
        "    axs[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    axs[i].view_init(elev=30, azim=45)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  ax1 = fig.add_subplot(int(f\"32{1+colNum}\"))\n",
        "  ax2 = fig.add_subplot(int(f\"32{3+colNum}\"))\n",
        "  ax3 = fig.add_subplot(int(f\"32{5+colNum}\"))\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  a = axs[0].contour(x_edges[:-1], y_edges[:-1], H_exp, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  b = axs[1].contour(x_edges[:-1], y_edges[:-1], H, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  c = axs[2].contour(x_edges[:-1], y_edges[:-1], H2, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H) ###Controls the contour lines\n",
        "\n",
        "  for n in range(len(axs)):\n",
        "    axs[n].set_aspect('equal')\n",
        "    #axs[n].set_xlim(x_lims[0],x_lims[1])\n",
        "    #axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    #axs[n].set_xlim(48, 58)\n",
        "    #axs[n].set_ylim(65, 75)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "  #cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  #plt.savefig(f\"230710_{aaName}_Urea.svg\", format='svg')\n",
        "\n",
        "  ##################################################################\n",
        "\n",
        "  ###End of function\n",
        "\n",
        "fig = plt.figure(figsize = (10, 10))\n",
        "\n",
        "for i in range(len(aaNameList)):\n",
        "  aaLetter = aaLetterList[i]\n",
        "  aaName = aaNameList[i]\n",
        "  print(aaName)\n",
        "\n",
        "  PDB_file = f\"{aaLetter}_10K.out\"\n",
        "  #exp_file = f\"NEW_2Xasyn30_reinstra_INADEQUATE_12kHZ_{aaName}.txt\"\n",
        "  exp_file = f\"2Xasyn30_reinstra_ff_INADEQUATE_12kHZ_{aaName}.txt\"\n",
        "  output_file_path = \"out\"\n",
        "  aa = aaLetter\n",
        "  main(PDB_file, exp_file, output_file_path, aa, i)\n",
        "\n",
        "plt.savefig(\"230713_NEW_COM_all_fwhm.png\", format='png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa, colNum):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 3) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  #j = y ###Might change in future?\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  #'A':[[44,61],[55,89],[170,184],[112,133]],\n",
        "                  'A':[[48,58],[67,77],[170,184],[112,133]],\n",
        "                  #'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'S':[[56,66],[118,128],[55,72],[167,181],[104,125]],\n",
        "                  #'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'T':[[57,67],[125,135],[60,77],[168,182],[102,123]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1][0])\n",
        "  x_lims[0] += -5\n",
        "  x_lims[1] += 5\n",
        "\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  y_lims[0] += -5\n",
        "  y_lims[1] += 5\n",
        "\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 2\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0] - adjDistX, x_lims[1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0], x_lims[1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2, y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "\n",
        "  #h_exp = H_exp\n",
        "  #####################################################################\n",
        "  H_exp1 = sp.ndimage.uniform_filter(H_exp, size=2, mode='constant')\n",
        "  H_exp2 = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  #H_exp = sp.ndimage.uniform_filter(H_exp, size=6, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "  H_exp_max1 = max([max(array) for array in H_exp1])\n",
        "  H_exp_max2 = max([max(array) for array in H_exp2])\n",
        "\n",
        "  d = []\n",
        "  dd = []\n",
        "\n",
        "  for i in range(len(H_exp1)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp1[i-1]) * H_exp_max / H_exp_max1\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "\n",
        "    cc = (H_exp2[i-1]) * H_exp_max / H_exp_max2\n",
        "    dd.append(cc)\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp1 = np.array(d)\n",
        "  H_exp2 = np.array(dd)\n",
        "\n",
        "\n",
        "  max_cont = np.max(H_exp)\n",
        "  min_cont = np.min(H_exp) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "  \"\"\"\n",
        "        # draw the subplot #\n",
        "  ax1 = fig.add_subplot(int(f\"33{1+colNum}\"), projection = '3d')\n",
        "  ax2 = fig.add_subplot(int(f\"33{4+colNum}\"), projection = '3d')\n",
        "  ax3 = fig.add_subplot(int(f\"33{7+colNum}\"), projection = '3d')\n",
        "  axs = [ax1, ax2, ax3]\n",
        "  HS = [H_exp, H_exp1, H_exp2]\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    axs[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    axs[i].view_init(elev=30, azim=45)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  ax1 = fig.add_subplot(int(f\"33{1+colNum}\"))\n",
        "  ax2 = fig.add_subplot(int(f\"33{4+colNum}\"))\n",
        "  ax3 = fig.add_subplot(int(f\"33{7+colNum}\"))\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  a = axs[0].contour(x_edges[:-1], y_edges[:-1], H_exp, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  b = axs[1].contour(x_edges[:-1], y_edges[:-1], H_exp1, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  c = axs[2].contour(x_edges[:-1], y_edges[:-1], H_exp2, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H_exp) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H_exp) ###Controls the contour lines\n",
        "\n",
        "  for n in range(len(axs)):\n",
        "    axs[n].set_aspect('equal')\n",
        "    axs[n].set_xlim(x_lims[0],x_lims[1])\n",
        "    axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    #axs[n].set_xlim(48, 58)\n",
        "    #axs[n].set_ylim(65, 75)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "  #cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  #plt.savefig(f\"230710_{aaName}_Urea.svg\", format='svg')\n",
        "\n",
        "  ##################################################################\n",
        "\n",
        "  ###End of function\n",
        "\n",
        "fig = plt.figure(figsize = (15, 15))\n",
        "\n",
        "for i in range(len(aaNameList)):\n",
        "  aaLetter = aaLetterList[i]\n",
        "  aaName = aaNameList[i]\n",
        "\n",
        "  PDB_file = f\"{aaLetter}_10K.out\"\n",
        "  exp_file = f\"230703_{aaName}_INADEQUATE_8M_Urea.txt\"\n",
        "  output_file_path = \"out\"\n",
        "  aa = aaLetter\n",
        "  main(PDB_file, exp_file, output_file_path, aa, i)\n",
        "\n",
        "plt.savefig(\"230711_COM_6810_filter.png\", format='png', dpi=300)\n",
        "#plt.savefig(\"230711_COM_024_filter.svg\", format='svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "btYbLt9hbkh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3x3 grid: 0 line broadening, 2 line broad, 4 line broad. 3d or contour\n"
      ],
      "metadata": {
        "id": "fuYtGPqLbceL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQT8Emg03yKX"
      },
      "outputs": [],
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 3) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  #j = y ###Might change in future?\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  #'A':[[44,61],[55,89],[170,184],[112,133]],\n",
        "                  'A':[[48,58],[67,77],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  #'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'S':[[56,66],[118,128],[55,72],[167,181],[104,125]],\n",
        "                  #'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'T':[[57,67],[125,135],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0][0],x_lims[0][1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0][0]+hw,x_lims[0][1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  # calculate counts for bins #\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "\n",
        "\n",
        "  H = H1\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 1.5  # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 2\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0][0] - adjDistX, x_lims[0][1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0][0], x_lims[0][1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2, y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequate, ca_exp, bins=(new_y_edges, new_x_edges), weights=intensity)\n",
        "  h = Z\n",
        "  c=[]\n",
        "  d =[]\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c=[]\n",
        "  d =[]\n",
        "  h_exp = H_exp\n",
        "  np.set_printoptions(threshold=np.inf)\n",
        "  #####################################################################\n",
        "  H_exp = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "  H_max = max([max(array) for array in H])\n",
        "  for i in range(len(H_exp)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp[i-1]) * H_max / H_exp_max\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp=np.array(d)\n",
        "  H_exp_max = max([max(array) for array in H_exp])\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "  h = np.subtract(H_exp,H)\n",
        "  savetxt(f'urea - {aaName}',h,delimiter=',')\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "\n",
        "  subplot_counter = 0\n",
        "        # draw the subplot #\n",
        "  fig, axs = plt.subplots(3, figsize=(10,10), tight_layout=True)\n",
        "\n",
        "  a = axs[0].contour(x_edges[:-1], y_edges[:-1], H_exp, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  b = axs[1].contour(x_edges[:-1], y_edges[:-1], H, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H) ###Controls the contour lines\n",
        "\n",
        "  c = axs[2].contour(x_edges[:-1], y_edges[:-1], h, levels = levels2, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  for n in range(3):\n",
        "    axs[n].set_aspect('equal')\n",
        "    axs[n].set_xlim(x_lims[0][0],aa_spec_ranges[aa1][0][1])\n",
        "    axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    #axs[n].set_xlim(48, 58)\n",
        "    #axs[n].set_ylim(65, 75)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "  cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  plt.savefig(f\"230710_{aaName}_Urea.svg\", format='svg')\n",
        "\n",
        "  ##################################################################\n",
        "\n",
        "  fig = plt.figure(figsize = (15, 5))\n",
        "  ax1 = fig.add_subplot(131, projection='3d')\n",
        "  ax2 = fig.add_subplot(132, projection = '3d')\n",
        "  ax3 = fig.add_subplot(133, projection = '3d')\n",
        "  AXS = [ax1, ax2, ax3]\n",
        "  HS = [H_exp, H, h]\n",
        "\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    AXS[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    AXS[i].view_init(elev=30, azim=45)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inputs = f\"{aaLetter}_10K.out,230703_{aaName}_INADEQUATE_8M_Urea.txt,out,{aaLetter}\".split(\",\")\n",
        "PDB_file = inputs[0]\n",
        "exp_file = inputs[1]\n",
        "output_file_path = inputs[2]\n",
        "aa = inputs[3]\n",
        "main(PDB_file, exp_file, output_file_path, aa)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOslQoOB_2u0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparisons of all of the THR/SER data\n"
      ],
      "metadata": {
        "id": "PIVPl48yy3SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def main(PDB_file, exp_file_arr, output_file_path, aa, colNum):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 3) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  dataArr = []\n",
        "  count = 0\n",
        "\n",
        "  for exp_file in exp_file_arr:\n",
        "    data = []\n",
        "    with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "      reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "      #print(infile.readlines())\n",
        "      for row in reader:\n",
        "        if len(row) == 1:\n",
        "          data.append(re.split(r'\\s+', row[0])[1:])\n",
        "        else:\n",
        "          data.append(row)\n",
        "    dataArr.append(data)\n",
        "\n",
        "  ca_expArr=[]\n",
        "  cb_expArr=[]\n",
        "  inadequateArr = []\n",
        "  intensityArr = []\n",
        "  for data in dataArr:\n",
        "    ca_exp = []\n",
        "    cb_exp = []\n",
        "    inadequate=[]\n",
        "    intensity=[]\n",
        "    for i in range(len(data)):\n",
        "      ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "      inadequate.append(float(data[i-1][1]))\n",
        "      cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "      intensity.append(float(data[i-1][2]))\n",
        "    ca_expArr.append(ca_exp)\n",
        "    cb_expArr.append(cb_exp)\n",
        "    inadequateArr.append(inadequate)\n",
        "    intensityArr.append(intensity)\n",
        "\n",
        "  for inadequate in inadequateArr:\n",
        "    for i in range(len(inadequate)):\n",
        "      inadequate[i-1] = inadequate[i-1]-1\n",
        "\n",
        "  for intentisty in intensityArr:\n",
        "    min = np.min(intensity)\n",
        "    for i in range(len(intensity)):\n",
        "      intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  #'A':[[44,61],[55,89],[170,184],[112,133]],\n",
        "                  'A':[[48,58],[67,77],[170,184],[112,133]],\n",
        "                  #'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'S':[[56,66],[118,128],[55,72],[167,181],[104,125]],\n",
        "                  #'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'T':[[57,67],[125,135],[60,77],[168,182],[102,123]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, y, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  x_lims = np.array(aa_spec_ranges[aa1][0])\n",
        "  x_lims[0] += -5\n",
        "  x_lims[1] += 5\n",
        "\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  y_lims[0] += -5\n",
        "  y_lims[1] += 5\n",
        "\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 2\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0] - adjDistX, x_lims[1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0], x_lims[1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2, y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "  H_expArr = []\n",
        "  for i in range(len(inadequateArr)):\n",
        "    H_exp, npxedges_exp, npyedges_exp = np.histogram2d(inadequateArr[i], ca_expArr[i], bins=(new_y_edges, new_x_edges), weights=intensityArr[i])\n",
        "    H_expArr.append(H_exp)\n",
        "\n",
        "  #h_exp = H_exp\n",
        "  #####################################################################\n",
        "  #H_exp1 = sp.ndimage.uniform_filter(H_exp, size=2, mode='constant')\n",
        "  #H_exp2 = sp.ndimage.uniform_filter(H_exp, size=4, mode='constant')\n",
        "\n",
        "  #H_exp = sp.ndimage.uniform_filter(H_exp, size=6, mode='constant')\n",
        "\n",
        "  ###Change this for varying heights for each graph\n",
        "  H_exp_max_Arr = []\n",
        "  for H_exp in H_expArr:\n",
        "    H_exp_max = max([max(array) for array in H_exp])\n",
        "    H_exp_max_Arr.append(H_exp_max)\n",
        "\n",
        "  d = []\n",
        "  dd = []\n",
        "\n",
        "  for i in range(len(H_expArr)):\n",
        "    c = []\n",
        "    for j in range(len(H_expArr[i])):\n",
        "      c.append((H_expArr[i][j-1]) * H_exp_max_Arr[0] / H_exp_max_Arr[i])\n",
        "\n",
        "    H_expArr[i] = c\n",
        "\n",
        "  \"\"\"for i in range(len(H_exp1)):\n",
        "    #c = (H_exp[i-1])/sum(sum(H_exp))\n",
        "    c = (H_exp1[i-1]) * H_exp_max / H_exp_max1\n",
        "    #c = (H_exp[i-1]*0.007033550868176652)/(sum(sum(h_exp))*0.0022451602109917292 )\n",
        "    d.append(c)\n",
        "\n",
        "    cc = (H_exp2[i-1]) * H_exp_max / H_exp_max2\n",
        "    dd.append(cc)\"\"\"\n",
        "  #####################################################################\n",
        "\n",
        "  H_exp1 = np.array(d)\n",
        "  H_exp2 = np.array(dd)\n",
        "\n",
        "\n",
        "  max_cont = np.max(H_expArr[0])\n",
        "  min_cont = np.min(H_expArr[0]) # ensemble_size/2000*(5units*bin_width)\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "  \"\"\"\n",
        "        # draw the subplot #\n",
        "  ax1 = fig.add_subplot(int(f\"33{1+colNum}\"), projection = '3d')\n",
        "  ax2 = fig.add_subplot(int(f\"33{4+colNum}\"), projection = '3d')\n",
        "  ax3 = fig.add_subplot(int(f\"33{7+colNum}\"), projection = '3d')\n",
        "  axs = [ax1, ax2, ax3]\n",
        "  HS = [np.array(H_expArr[0]), np.array(H_expArr[1]), np.array(H_expArr[2])]\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    axs[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    axs[i].view_init(elev=30, azim=45)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  ax1 = fig.add_subplot(int(f\"33{1+colNum}\"))\n",
        "  ax2 = fig.add_subplot(int(f\"33{4+colNum}\"))\n",
        "  ax3 = fig.add_subplot(int(f\"33{7+colNum}\"))\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  for i in range(len(axs)):\n",
        "    axs[i].contour(x_edges[:-1], y_edges[:-1], H_expArr[i], levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H_expArr[0]) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H_expArr[0]) ###Controls the contour lines\n",
        "\n",
        "  for n in range(len(axs)):\n",
        "    axs[n].set_aspect('equal')\n",
        "    axs[n].set_xlim(x_lims[0],x_lims[1])\n",
        "    axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    #axs[n].set_xlim(48, 58)\n",
        "    #axs[n].set_ylim(65, 75)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "  #cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  #plt.savefig(f\"230710_{aaName}_Urea.svg\", format='svg')\n",
        "\n",
        "  ##################################################################\n",
        "\n",
        "  ###End of function\n",
        "\n",
        "fig = plt.figure(figsize = (15, 15))\n",
        "\n",
        "for i in range(len(aaNameList)):\n",
        "  aaLetter = aaLetterList[i]\n",
        "  aaName = aaNameList[i]\n",
        "\n",
        "  PDB_file = f\"{aaLetter}_10K.out\"\n",
        "  exp_fileArr = [f\"230703_{aaName}_INADEQUATE_8M_Urea.txt\", f\"2Xasyn30_reinstra_ff_INADEQUATE_12kHZ_{aaName}.txt\", f\"NEW_2Xasyn30_reinstra_INADEQUATE_12kHZ_{aaName}.txt\"]\n",
        "  output_file_path = \"out\"\n",
        "  aa = aaLetter\n",
        "  main(PDB_file, exp_fileArr, output_file_path, aa, i)\n",
        "\n",
        "#plt.savefig(\"230713_COM_data.png\", format='png', dpi=300)\n",
        "plt.savefig(\"230713_COM_data.svg\", format='svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WzjuVAZ5y6MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is needed:\n",
        "\n",
        "*   Comparison of 1.5 fwhm to 3 fwhm (predicted, both 2d histogram + contour)\n",
        "*   Comparison of line broadening (experimental, final?, both 2d histogram + countour)\n",
        "*   Comparison of shifts needed (compare peaks?)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vpXnpYU7MubS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oNHdL1WNNS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random comparison between y and z and y+z"
      ],
      "metadata": {
        "id": "18hWHIb3u0oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(PDB_file, exp_file, output_file_path, aa, colNum):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(PDB_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "  x = get_row_floats(data[1:], 2)\n",
        "  y = get_row_floats(data[1:], 3) ###Might change in future\n",
        "  z = get_row_floats(data[1:], 4)\n",
        "  w = get_row_floats(data[1:], 5)\n",
        "\n",
        "  j = []\n",
        "  for i in range(len(x)):\n",
        "    j.append(x[i] + y[i])\n",
        "\n",
        "  #j = y ###Might change in future?\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  with open(exp_file, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    #print(infile.readlines())\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split(r'\\s+', row[0])[1:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "\n",
        "  ca_exp=[]\n",
        "  inadequate=[]\n",
        "  cb_exp=[]\n",
        "  intensity=[]\n",
        "  for i in range(len(data)):\n",
        "    ca_exp.append(float(data[i-1][0])) #def x as Ca shift\n",
        "    inadequate.append(float(data[i-1][1]))\n",
        "    cb_exp.append(float(data[i-1][1])) #def y as Cb shift\n",
        "    intensity.append(float(data[i-1][2]))\n",
        "\n",
        "  for i in range(len(inadequate)):\n",
        "    inadequate[i-1] = inadequate[i-1]-1\n",
        "  min = np.min(intensity)\n",
        "  for i in range(len(intensity)):\n",
        "    intensity[i-1] = intensity[i-1]-min\n",
        "\n",
        "  mask = np.logical_and(np.array(inadequate) >= 29, np.array(inadequate) <= 37)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) >= 54)\n",
        "  mask = np.logical_and(mask, np.array(ca_exp) <= 71)\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "  na=np.nan\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca   inadequate   Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                  #'A':[[44,61],[55,89],[11,28],[170,184],[112,133]],\n",
        "                  # swapped Ca and Cb for A\n",
        "                   'A':[[11,28],[67,77],[48,58],[112,133]],\n",
        "                  #'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'S':[[56,66],[118,128],[55,72],[167,181],[104,125]],\n",
        "                  #'T':[[54,71],[114,148],[60,77],[168,182],[102,123]],\n",
        "                  'T':[[57,67],[128,138],[60,77],[168,182],[102,123]],\n",
        "                  }\n",
        "  aa_atom_groups={\n",
        "                  'A':[['co','ca'],['ca','cb']],\n",
        "  #               'C':[['co','ca'],['ca','cb']],\n",
        "                  'D':[['co','ca'],['ca','cb']],\n",
        "                  'E':[['co','ca'],['ca','cb']],\n",
        "                  'F':[['co','ca'],['ca','cb']],\n",
        "                  'G':[['co','ca']],\n",
        "                  'H':[['co','ca'],['ca','cb']],\n",
        "                  'I':[['co','ca'],['ca','cb']],\n",
        "                  'K':[['co','ca'],['ca','cb']],\n",
        "                  'L':[['co','ca'],['ca','cb']],\n",
        "                  'M':[['co','ca'],['ca','cb']],\n",
        "                  'N':[['co','ca'],['ca','cb']],\n",
        "                  'P':[['co','ca'],['ca','cb']],\n",
        "                  'Q':[['co','ca'],['ca','cb']],\n",
        "                  'R':[['co','ca'],['ca','cb']],\n",
        "                  'S':[['co','ca'],['ca','cb']],\n",
        "                  'T':[['co','ca'],['ca','cb']],\n",
        "                  'V':[['co','ca'],['ca','cb']],\n",
        "                  'Y':[['co','ca'],['ca','cb']],\n",
        "                  'W':[['co','ca'],['ca','cb']],\n",
        "                }\n",
        "  atom_a = \"ca\" #defining atom_a as the alpha carbon\n",
        "  atom_b = \"cb\" #defining atom_b as the beta carbon\n",
        "  aaX = aa1 #define aaX as residue of interest (one letter code)\n",
        "  points = zip(atom_a, atom_b) #create an array with both atom_a and atom_b\n",
        "\n",
        "  aaX = aa\n",
        "  subplot_counter = 0\n",
        "  aaX = aa1\n",
        "  atom_a = atom_a.lower(); atom_b = atom_b.lower()#\n",
        "\n",
        "  CAs=[]; CBs=[]; COs=[]; Ns=[]\n",
        "\n",
        "  # join CS of each atom into one list #\n",
        "  if aa1 in nonCys_nonGly_aas:\n",
        "          all_CS = [x, j, y, z]\n",
        "  elif aa1 == 'G':\n",
        "          all_CS = [x, j, y, w] ###Relevant?\n",
        "  elif aa1 == 'C':\n",
        "          print('Skipping cysteine since PPM has no prediction for Cys.')\n",
        "  else:\n",
        "          print('Error: amino acid \\\"{}\\\" not implemented'.format(aa1))\n",
        "          sys.exit()\n",
        "\n",
        "  x_key=atom_key[atom_a]\n",
        "  y_key=atom_key[atom_b]\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "\n",
        "  ###changes for combining ca and cb###\n",
        "  #make x lim minimum to be aa_spec_ranges[aa1][0][0] and max is aa_spec_ranges[aa1][2][1]\n",
        "  x_lims = np.array([aa_spec_ranges[aa1][0][0],aa_spec_ranges[aa1][2][1]])\n",
        "  print(x_lims)\n",
        "  #x_lims[0] += -5\n",
        "  #x_lims[1] += 5\n",
        "\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1]) ####changed\n",
        "  #y_lims[0] += -5\n",
        "  #y_lims[1] += 5\n",
        "\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "\n",
        "  #we'll just create a new histogram for cb data\n",
        "  # calculate counts for bins #\n",
        "  print(j)\n",
        "  print(x)\n",
        "\n",
        "  H1, npxedges, npyedges = np.histogram2d(j, x,\n",
        "                                          bins=(y_edges,x_edges))#, weights = [w[i]]*len(all_CS[y_key]),)\n",
        "  H2, npxedges, npyedges = np.histogram2d(j, y,\n",
        "                                          bins=(y_edges,x_edges))\n",
        "  H = H1 #add together arrays later so memory isn't wasted on the gaussian\n",
        "  #create new array of H1 and H2 but in 1 dimension\n",
        "\n",
        "  #print(H)\n",
        "\n",
        "  h_lists = []\n",
        "  h = []\n",
        "\n",
        "  fwhm = 1.5  # Full width at half maximum\n",
        "  def gaussian2d(x, y, amplitude, xo, yo, fwhm):\n",
        "    d = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "    h_list = [0]*len(H)\n",
        "    xgrid, ygrid = np.meshgrid(x, y)\n",
        "    g = np.zeros_like(xgrid)\n",
        "    for i in range(len(xo)-1):\n",
        "        for j in range(len(yo)-1):\n",
        "            a = 1/(2*d**2)\n",
        "            c = 1/(2*d**2)\n",
        "            xi = np.linspace(xo[i] - 3 * d, xo[i] + 3 * d, len(xo))\n",
        "            yi = np.linspace(yo[j] - 3 * d, yo[j] + 3 * d, len(yo))\n",
        "            xigrid, yigrid = np.meshgrid(xi, yi)\n",
        "            gi = amplitude[i][j]*np.exp( - (a*((xigrid-xo[i])**2) + a*((yigrid-yo[j])**2)))\n",
        "            H3, npxedges1, npyedges1 = np.histogram2d(yigrid.ravel(),xigrid.ravel(),bins=(npyedges,npxedges),weights = gi.ravel())\n",
        "            h_list.append(H3)\n",
        "    h_lists.append(sum(h_list))\n",
        "    h = sum(h_lists)\n",
        "    return(h)\n",
        "\n",
        "  Z = gaussian2d(npxedges[:-1], npyedges[:-1], H1, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "  Z2 = gaussian2d(npxedges[:-1], npyedges[:-1], H1, npxedges[:-1], npyedges[:-1], fwhm * 2)\n",
        "\n",
        "  Y = gaussian2d(npxedges[:-1], npyedges[:-1], H2, npxedges[:-1], npyedges[:-1], fwhm)\n",
        "  Y2 = gaussian2d(npxedges[:-1], npyedges[:-1], H2, npxedges[:-1], npyedges[:-1], fwhm * 2)\n",
        "\n",
        "\n",
        "  h = np.sum((Z, Y), axis=0)\n",
        "\n",
        "  h = Y\n",
        "\n",
        "  c=[]\n",
        "  d = []\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H=np.array(d).T\n",
        "  c = []\n",
        "  d = []\n",
        "\n",
        "\n",
        "  h = np.sum((Z2, Y2), axis = 0)\n",
        "\n",
        "  h = Z\n",
        "\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H2 = np.array(d).T\n",
        "  c = []\n",
        "  d = []\n",
        "\n",
        "\n",
        "  h = np.sum((Y, Z), axis = 0)\n",
        "  for i in range(len(h)):\n",
        "    c = h[i-1]/sum(sum(h))\n",
        "    d.append(c)\n",
        "  H3 = np.array(d).T\n",
        "  c = []\n",
        "  d = []\n",
        "\n",
        "\n",
        "  #H2 = np.flipud(np.fliplr(H2))\n",
        "\n",
        "  ### Adjusting the spectra measured for the experimental\n",
        "  adjDistX = 0\n",
        "  adjDistY = 0\n",
        "  adjDistY /= 2\n",
        "  new_x_edges = np.arange(x_lims[0] - adjDistX, x_lims[1] - adjDistX + bin_width,bin_width)\n",
        "  #x_edges = np.arange(x_lims[0], x_lims[1] + bin_width,bin_width)\n",
        "  new_y_edges=np.arange(y_lims[0] - adjDistY * 2, y_lims[1] - adjDistY * 2 + bin_width,bin_width)\n",
        "  ###\n",
        "\n",
        "\n",
        "\n",
        "  def index_2d(myList, v):\n",
        "    for i, x in enumerate(myList):\n",
        "        if v in x:\n",
        "            return (i, x.index(v))\n",
        "\n",
        "  #print(f\"{np.where(H_exp == H_exp_max)}, {np.where(H == H_max)}\")\n",
        "  ###subtraction###\n",
        "\n",
        "  max_cont = np.max(H)\n",
        "\n",
        "  #ensemble_size = len(all_CS[y_key])\n",
        "  #factor size of 1.15\n",
        "  #13steps\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  step = []\n",
        "\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "\n",
        "  levels = array\n",
        "  min_cont = np.min(h) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(h) ###Controls the contour lines\n",
        "\n",
        "  step = []\n",
        "  for i in range(13):\n",
        "    x = 1.15**i\n",
        "    step.append(x)\n",
        "  steps = sum(step)\n",
        "  step_cont = np.subtract(max_cont,min_cont)/steps\n",
        "  array = np.zeros(13)\n",
        "\n",
        "  for i in range(13):\n",
        "    if i == 0:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + min_cont\n",
        "    else:\n",
        "      array[i] = (((1.15 ** i) * (step_cont))) + array[i-1]\n",
        "  levels2 = array\n",
        "\n",
        "\n",
        "        # draw the subplot #\n",
        "  \"\"\"\n",
        "  ax1 = fig.add_subplot(int(f\"32{1+colNum}\"), projection = '3d')\n",
        "  ax2 = fig.add_subplot(int(f\"32{3+colNum}\"), projection = '3d')\n",
        "  ax3 = fig.add_subplot(int(f\"32{5+colNum}\"), projection = '3d')\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  HS = [H_exp, H, H2]\n",
        "\n",
        "  xedges = new_x_edges\n",
        "  yedges = new_y_edges\n",
        "\n",
        "  xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
        "\n",
        "  xpos = xpos.flatten()/2.\n",
        "  ypos = ypos.flatten()/2.\n",
        "  zpos = np.zeros_like(xpos)\n",
        "\n",
        "  dx = xedges [1] - xedges [0]\n",
        "  dy = yedges [1] - yedges [0]\n",
        "\n",
        "  for i in range(len(HS)):\n",
        "    dz = HS[i].flatten()\n",
        "    cmap = cm.jet # Get desired colormap - you can change this!\n",
        "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
        "    min_height = np.min(dz)\n",
        "    # scale each z to [0,1], and get their rgb values\n",
        "    rgba = [cmap((k-min_height)/max_height) for k in dz]\n",
        "\n",
        "    axs[i].bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
        "    axs[i].view_init(elev=30, azim=45)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  ax1 = fig.add_subplot(int(f\"32{1+colNum}\"))\n",
        "  ax2 = fig.add_subplot(int(f\"32{3+colNum}\"))\n",
        "  ax3 = fig.add_subplot(int(f\"32{5+colNum}\"))\n",
        "  axs = [ax1, ax2, ax3]\n",
        "\n",
        "  a = axs[0].contour(x_edges[:-1], y_edges[:-1], H3, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  b = axs[1].contour(x_edges[:-1], y_edges[:-1], H, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "  c = axs[2].contour(x_edges[:-1], y_edges[:-1], H2, levels = levels, cmap='RdBu',linewidths=0.5)\n",
        "\n",
        "  min_cont = np.min(H) # ensemble_size/2000*(5units*bin_width)\n",
        "  max_cont = np.max(H) ###Controls the contour lines\n",
        "\n",
        "  for n in range(len(axs)):\n",
        "    axs[n].set_aspect('equal')\n",
        "    #axs[n].set_xlim(x_lims[0],x_lims[1])\n",
        "    #axs[n].set_ylim(y_lims[0],y_lims[1])\n",
        "    #axs[n].set_xlim(48, 58)\n",
        "    #axs[n].set_ylim(65, 75)\n",
        "    axs[n].xaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].yaxis.set_major_locator(pltticker.MultipleLocator(mtick_spacing))\n",
        "    axs[n].xaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].yaxis.set_minor_locator(pltticker.MultipleLocator(1))\n",
        "    axs[n].set_xlabel('ppm', labelpad=1.0)\n",
        "    axs[n].set_ylabel('ppm', labelpad=1.0)\n",
        "    axs[n].invert_xaxis()\n",
        "    axs[n].invert_yaxis()\n",
        "\n",
        "  #cbar = plt.colorbar(c)\n",
        "  #cbar2 = plt.colorbar(b)\n",
        "  ###Change this eventually\n",
        "  #plt.savefig(f\"230710_{aaName}_Urea.svg\", format='svg')\n",
        "\n",
        "  ##################################################################\n",
        "\n",
        "  ###End of function\n",
        "\n",
        "fig = plt.figure(figsize = (10, 10))\n",
        "\n",
        "for i in range(len(aaNameList)):\n",
        "  aaLetter = aaLetterList[i]\n",
        "  aaName = aaNameList[i]\n",
        "  print(aaName)\n",
        "\n",
        "  PDB_file = f\"{aaLetter}_10K.out\"\n",
        "  exp_file = f\"NEW_2Xasyn30_reinstra_INADEQUATE_12kHZ_{aaName}.txt\"\n",
        "  output_file_path = \"out\"\n",
        "  aa = aaLetter\n",
        "  main(PDB_file, exp_file, output_file_path, aa, i)\n",
        "\n",
        "plt.savefig(\"230713_NEW_COM_all_fwhm.png\", format='png', dpi = 300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PL6maFtnu3wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gMw5rcou9pA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}