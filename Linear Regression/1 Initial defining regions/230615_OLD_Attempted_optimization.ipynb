{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erictong0/FrederickLab2023/blob/main/Linear%20Regression/Initial%20defining%20regions/230615_OLD_Attempted_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bio --upgrade"
      ],
      "metadata": {
        "id": "0f1bVLTVsD23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install line_profiler\n",
        "!pip install scipy\n",
        "%load_ext line_profiler"
      ],
      "metadata": {
        "id": "S6cQgnoaHDZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as pltticker\n",
        "import csv\n",
        "from matplotlib import colors\n",
        "import re\n",
        "import pandas as pd\n",
        "from numpy import savetxt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statistics import mean\n",
        "import statsmodels.api as sm\n",
        "from Bio.Data.IUPACData import protein_letters_1to3 as one2three\n",
        "import line_profiler\n",
        "import scipy.optimize as spo"
      ],
      "metadata": {
        "id": "JTooop-BN1og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fwhm = 1.5  # Full width at half maximum\n",
        "# Calculate the standard deviation from the FWHM\n",
        "c = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "xArray = []\n",
        "for i in range(68):\n",
        "  b = i / 4 + 54\n",
        "  xArray.append(np.linspace(b - 3 * c, b + 3 * c, 100))\n",
        "\n",
        "oData = []\n",
        "data = []\n",
        "with open(\"T_10K.out\", mode=\"r\") as infile: #open data file and read contents\n",
        "  reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "  for row in reader:\n",
        "    if len(row) == 1:\n",
        "      data.append(re.split('\\t', row[0])[2:])\n",
        "    else:\n",
        "      data.append(row)\n",
        "\n",
        "def get_row_floats(data, row):\n",
        "  return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "tempData = []\n",
        "for i in range(6):\n",
        "  tempData.append(get_row_floats(data[1:], i))\n",
        "\n",
        "oData.append(tempData)\n",
        "\n",
        "data = []\n",
        "tempData = []\n",
        "count = 0\n",
        "with open(\"nanodisc.csv\", mode=\"r\") as infile: #open data file and read contents\n",
        "  chunk_size = 1000\n",
        "  while True:\n",
        "      chunk = infile.readlines(chunk_size)\n",
        "      if not chunk:\n",
        "        break\n",
        "      for line in chunk:\n",
        "        reader = csv.reader(infile)\n",
        "        for row in reader:\n",
        "          count += 1\n",
        "          if len(row) == 1:\n",
        "            tempData.append(re.split(r',', row[0]))\n",
        "          else:\n",
        "            tempData.append(row)\n",
        "\n",
        "data.append(get_row_floats(tempData,0))\n",
        "data.append(get_row_floats(tempData,2))\n",
        "\n",
        "oData.append(data)\n",
        "\n",
        "DATAINPUT = oData"
      ],
      "metadata": {
        "id": "u9hFf9VHOHF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phi = DATAINPUT[0][0]\n",
        "psi = DATAINPUT[0][1]\n",
        "ca = DATAINPUT[0][2]\n",
        "cb = DATAINPUT[0][3]\n",
        "c = DATAINPUT[0][4]\n",
        "n = DATAINPUT[0][5]\n"
      ],
      "metadata": {
        "id": "8R-TC0fEOi0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_QemTFWGUur"
      },
      "outputs": [],
      "source": [
        "def main(inData, aa, rangeChoices):\n",
        "  aa1 = aa\n",
        "\n",
        "  phi = inData[0][0]\n",
        "  psi = inData[0][1]\n",
        "  ca = inData[0][2]\n",
        "  cb = inData[0][3]\n",
        "  c = inData[0][4]\n",
        "  n = inData[0][5]\n",
        "\n",
        "\n",
        "\n",
        "  ca_exp = inData[1][0] #def x as Ca shift\n",
        "  intensity = inData[1][1]\n",
        "\n",
        "\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  na=np.nan\n",
        "\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                 'A':[[11,28],[203,234],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,71],[104,138],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "\n",
        "  ####Changed this part####\n",
        "  rchoice = rangeChoices\n",
        "\n",
        "  ### extract plot subregions ###\n",
        "  # \"r\" stands for ramachandran\n",
        "  # regions: beta-strand, polyproline helix ii\n",
        "  #          beta-turn I, alpha-helix,\n",
        "  #          left handed helix (all phi > 0)\n",
        "  # !!! top and left corner are always >= or <=\n",
        "  #     unless they reach the bottom/right axis\n",
        "  #     (i.e. betaB, ppiiB, left)\n",
        "\n",
        "  #filter beta regions\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rbetaA'][0], np.array(phi) <= rchoice['rbetaA'][1])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rbetaA'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rbetaA'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['rbetaB'][0], np.array(phi) <= rchoice['rbetaB'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rbetaB'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rbetaB'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, mask2)\n",
        "\n",
        "  data_beta_ca = np.array(ca)[mask]\n",
        "  data_beta_cb = np.array(cb)[mask]\n",
        "  data_beta_c = np.array(c)[mask]\n",
        "  data_beta_n = np.array(n)[mask]\n",
        "\n",
        "  #filter ppii regions\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rppiiA'][0], np.array(phi) <= rchoice['rppiiA'][1])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rppiiA'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rppiiA'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['rppiiB'][0], np.array(phi) <= rchoice['rppiiB'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rppiiB'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rppiiB'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, mask2)\n",
        "\n",
        "  data_ppii_ca = np.array(ca)[mask]\n",
        "  data_ppii_cb = np.array(cb)[mask]\n",
        "  data_ppii_c = np.array(c)[mask]\n",
        "  data_ppii_n = np.array(n)[mask]\n",
        "\n",
        "  #filter ddgg\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['rdelta'][0], np.array(phi) <= rchoice['rdelta'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) >= rchoice['rdelta'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['rdelta'][3])\n",
        "\n",
        "  data_ddgg_ca = np.array(ca)[mask]\n",
        "  data_ddgg_cb = np.array(cb)[mask]\n",
        "  data_ddgg_c = np.array(c)[mask]\n",
        "  data_ddgg_n = np.array(n)[mask]\n",
        "\n",
        "  #filter turn\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rturnI'][0], np.array(phi) < rchoice['ralpha'][0])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['ralpha'][1], np.array(phi) < rchoice['rturnI'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask3 = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask3 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask3 = np.logical_and(mask1, np.array(psi) <= rchoice['ralpha'][2])\n",
        "\n",
        "  mask4 = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask4 = np.logical_and(mask1, np.array(psi) > rchoice['ralpha'][3])\n",
        "  mask4 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, np.logical_or(mask2, np.logical_or(mask3, mask4)))\n",
        "  data_turn_ca = np.array(ca)[mask]\n",
        "  data_turn_cb = np.array(cb)[mask]\n",
        "  data_turn_c = np.array(c)[mask]\n",
        "  data_turn_n = np.array(n)[mask]\n",
        "\n",
        "  #filter alph\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) > rchoice['ralpha'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['ralpha'][3])\n",
        "\n",
        "  data_alph_ca = np.array(ca)[mask]\n",
        "  data_alph_cb = np.array(cb)[mask]\n",
        "  data_alph_c = np.array(c)[mask]\n",
        "  data_alph_n = np.array(n)[mask]\n",
        "\n",
        "  #filter left\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['rlhelx'][0], np.array(phi) <= rchoice['rlhelx'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) >= rchoice['rlhelx'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['rlhelx'][3])\n",
        "\n",
        "  data_left_ca = np.array(ca)[mask]\n",
        "  data_left_cb = np.array(cb)[mask]\n",
        "  data_left_c = np.array(c)[mask]\n",
        "  data_left_n = np.array(n)[mask]\n",
        "\n",
        "\n",
        "  # create dictionaries of data sets\n",
        "\n",
        "  cs_ca = ({'beta': data_beta_ca,\n",
        "            'ppii': data_ppii_ca,\n",
        "            'ddgg': data_ddgg_ca,\n",
        "            'left': data_left_ca,\n",
        "            'turn': data_turn_ca,\n",
        "            'alph': data_alph_ca,\n",
        "            })\n",
        "  cs_cb = ({'beta': data_beta_cb,\n",
        "            'ppii': data_ppii_cb,\n",
        "            'ddgg': data_ddgg_cb,\n",
        "            'left': data_left_cb,\n",
        "            'turn': data_turn_cb,\n",
        "            'alph': data_alph_cb,\n",
        "            })\n",
        "  cs_co = ({'beta': data_beta_c,\n",
        "            'ppii': data_ppii_c,\n",
        "            'ddgg': data_ddgg_c,\n",
        "            'left': data_left_c,\n",
        "            'turn': data_turn_c,\n",
        "            'alph': data_alph_c,\n",
        "            })\n",
        "\n",
        "  cs_all = {'ca':cs_ca,\n",
        "            'cb':cs_cb,\n",
        "            'c' :cs_co,\n",
        "            }\n",
        "\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  #fig, axs = plt.subplots(1, 1, sharey=False, tight_layout=True,figsize=(10,10)) #35826579\n",
        "\n",
        "  x_lims = np.array(aa_spec_ranges[aa1][0])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "  inputs = []\n",
        "  h_lists = []\n",
        "  h_list = []\n",
        "\n",
        "  for key in cs_ca:\n",
        "    H, bins = np.histogram(cs_ca[key],bins=(x_edges),density=False)\n",
        "    for j in range(len(H)):\n",
        "      a = H[j]  # Maximum value\n",
        "      b = bins[j]  # Peak position\n",
        "      c = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "\n",
        "      x = xArray[round(b*4-216)]\n",
        "\n",
        "\n",
        "      # Calculate the y values for the curve using the Gaussian function\n",
        "      y = a * np.exp(-(x - b)**2 / (2 * c**2))\n",
        "\n",
        "      histogram, bins = np.histogram(x, bins=x_edges, density=False, weights = y)\n",
        "      h_list.append(histogram)\n",
        "\n",
        "    h_lists = sum(h_list)\n",
        "    inputs.append(h_lists)\n",
        "    #h_lists = []\n",
        "\n",
        "  #print(inputs)\n",
        "  H_exp, bins = np.histogram(ca_exp,bins=(x_edges),density=False)\n",
        "  target = (H_exp)\n",
        "  hists1 = (inputs[0])\n",
        "  hists2 = (inputs[1])\n",
        "  hists3 = (inputs[2])\n",
        "  hists4 = (inputs[3])\n",
        "  hists5 = (inputs[4])\n",
        "  hists6 = (inputs[5])\n",
        "  #print(np.shape(inputs),len(inputs[0]),len(target))\n",
        "  data = {'x1': list(hists1), 'x2': list(hists2), 'x3': list(hists3), 'x4':list(hists4), 'x5':hists5, 'x6':list(hists6), 'y': list(target) }\n",
        "  df = pd.DataFrame(data)\n",
        "  x = df[['x1','x2','x3','x4','x5','x6']]\n",
        "  y = df['y']\n",
        "\n",
        "\n",
        "  model = sm.GLS(y,x)\n",
        "  results = model.fit()\n",
        "  return results.rsquared\n",
        "\n",
        "#new code starts here\n",
        "def returnDict(params):\n",
        "  topSep = params[0]\n",
        "  topH = params[1]\n",
        "  middleH = params[2]\n",
        "  botSep = params[3]\n",
        "  botH = params[4]\n",
        "  return {\n",
        "      #upper left\n",
        "      'rbetaA':(-180.0, topSep, topH, 180.0),\n",
        "      'rppiiA':( topSep,   0.0, topH, 180.0),\n",
        "\n",
        "      #Middle\n",
        "      'rdelta':(-180.0,   0.0,  middleH, 105.0),\n",
        "\n",
        "      #large middle box\n",
        "      'rturnI':(-180.0,   0.0, botH,  middleH), # turn is wider alpha\n",
        "\n",
        "      #smaller tiny box\n",
        "      'ralpha':(-40, -35, -100, -50), # alph is strictly alpha\n",
        "\n",
        "      #bottom left\n",
        "      'rbetaB':(-180.0, botSep,-180.0, botH),\n",
        "      'rppiiB':(botSep,    0.0,-180.0, botH),\n",
        "\n",
        "      'rlhelx':(   0.0, 180.0,-180.0, 180.0),\n",
        "  }\n",
        "\n",
        "def func(params):\n",
        "  #topSep, topH, middleH, botSep, botH\n",
        "  theDict = returnDict(params)\n",
        "  r = main(DATAINPUT, \"T\", theDict)\n",
        "  return r * -1\n",
        "\n",
        "guess = [-115, 130, -20, -145, -60]\n",
        "bounds = ((-116, -114), (129, 131), (-21, -19), (-146, -144), (-61, -59))\n",
        "result = spo.basinhopping(func, guess)\n",
        "print(result.x)\n",
        "print(result.fun)\n",
        "print(returnDict(result.x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(returnDict(result.x))"
      ],
      "metadata": {
        "id": "7AnBnbS7kg4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/47055970/how-can-i-write-bounds-of-parameters-by-using-basinhopping"
      ],
      "metadata": {
        "id": "IIXqO5i9j9_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aDict = returnDict(-120, 150, 0, -120, -90)<br>\n",
        "\n",
        "%lprun -f main main(DATAINPUT, \"T\", aDict)"
      ],
      "metadata": {
        "id": "W4Jl9FHvhHmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\"\"\"for topSep in range(-150, -89, 30):\n",
        "  print(f\"{topSep}: \")\n",
        "  for topH in range(90, 151, 30):\n",
        "    for botSep in range(-120, -59, 30):\n",
        "      for botH in range(-150, -89, 30):\n",
        "        for middleH in range(botH + 30, topH - 29, 30):\n",
        "          #r = main(\"T_10K.out\", \"nanodisc.csv\", \"T\", returnDict(-180, 105, 45, -105, -150))\n",
        "          #print(r)\n",
        "          theDict = returnDict(topSep, topH, middleH, botSep, botH)\n",
        "          r = main(\"T_10K.out\", \"nanodisc.csv\", \"T\", theDict)\n",
        "          if r > bestR:\n",
        "            print(f\"{str(round(r, 3))}: {topSep}/{topH}/{botSep}/{botH}/{middleH}\")\n",
        "            bestR = r\n",
        "            bestDict = theDict\n",
        "    print(topH, end = \"\")\"\"\""
      ],
      "metadata": {
        "id": "3o3OwXCbLJlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.47: -150/90/-120/-150/-120 <br>\n",
        "0.475: -150/90/-120/-150/-90 <br>\n",
        "0.48: -150/90/-120/-150/-60 <br>\n",
        "0.493: -150/90/-120/-150/0 <br>\n",
        "0.494: -150/90/-120/-120/0\n"
      ],
      "metadata": {
        "id": "rjuya5NL8qKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "random code for things:\n",
        "\n",
        "tempDict = {\n",
        "    #upper left\n",
        "    'rbetaA':(-180.0, -140.0, 105.0, 180.0),\n",
        "    'rppiiA':( -140.0,   0.0, 105.0, 180.0),\n",
        "\n",
        "    #Middle\n",
        "    'rdelta':(-180.0,   0.0,  45.0, 105.0),\n",
        "\n",
        "    #large middle box\n",
        "    'rturnI':(-180.0,   0.0,-150.0,  45.0), # turn is wider alpha\n",
        "    #smaller tiny box\n",
        "    'ralpha':( -90, -30, -60.0, -20.0), # alph is strictly alpha\n",
        "\n",
        "    #bottom left\n",
        "    'rbetaB':(-180.0,-105.0,-180.0,-150.0),\n",
        "    'rppiiB':(-105.0,   0.0,-180.0,-150.0),\n",
        "\n",
        "    'rlhelx':(   0.0, 180.0,-180.0, 180.0),\n",
        "    }"
      ],
      "metadata": {
        "id": "7jSZpnmu2nTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0\n",
        "for topSep in range(-130, -109, 5):\n",
        "  print(f\"Outer: {topSep}/-110 \\n\")\n",
        "  for topH in range(140, 161, 5):\n",
        "    for middleH in range(-10, 11, 5):\n",
        "      for botSep in range(-130, -109, 5):\n",
        "        for botH in range(-100, -79, 5):\n",
        "          x += 1\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "id": "IZPosvC_ZJVh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}