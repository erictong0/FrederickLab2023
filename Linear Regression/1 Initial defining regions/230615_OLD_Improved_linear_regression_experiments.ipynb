{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erictong0/FrederickLab2023/blob/main/Linear%20Regression/Initial%20defining%20regions/230615_OLD_Improved_linear_regression_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f1bVLTVsD23"
      },
      "outputs": [],
      "source": [
        "!pip install bio --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_QemTFWGUur"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as pltticker\n",
        "import csv\n",
        "from matplotlib import colors\n",
        "import re\n",
        "import pandas as pd\n",
        "from numpy import savetxt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statistics import mean\n",
        "import statsmodels.api as sm\n",
        "from Bio.Data.IUPACData import protein_letters_1to3 as one2three\n",
        "def main(input_file_path, input_exp, aa, rangeChoices):\n",
        "  aa1 = aa\n",
        "  data = []\n",
        "  with open(input_file_path, mode=\"r\") as infile: #open data file and read contents\n",
        "    reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "    for row in reader:\n",
        "      if len(row) == 1:\n",
        "        data.append(re.split('\\t', row[0])[2:])\n",
        "      else:\n",
        "        data.append(row)\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "  ca = get_row_floats(data[1:], 2) #def x as Ca shift\n",
        "  cb = get_row_floats(data[1:], 3) #def y as Cb shift\n",
        "  c = get_row_floats(data[1:], 4) #def z as CO shift\n",
        "  n = get_row_floats(data[1:], 5) #def w as N shift\n",
        "  phi = get_row_floats(data[1:], 0)\n",
        "  psi = get_row_floats(data[1:], 1)\n",
        "\n",
        "  data = []\n",
        "  count = 0\n",
        "  with open(input_exp, mode=\"r\") as infile: #open data file and read contents\n",
        "    chunk_size = 1000\n",
        "    while True:\n",
        "        chunk = infile.readlines(chunk_size)\n",
        "        if not chunk:\n",
        "          break\n",
        "        for line in chunk:\n",
        "          reader = csv.reader(infile)\n",
        "          for row in reader:\n",
        "            count += 1\n",
        "            if len(row) == 1:\n",
        "              data.append(re.split(r',', row[0]))\n",
        "            else:\n",
        "              data.append(row)\n",
        "  def get_row_floats(data, row):\n",
        "    return list(map(lambda x: float(x[row]), data))\n",
        "  ca_exp = get_row_floats(data,0) #def x as Ca shift\n",
        "  intensity = get_row_floats(data,2)\n",
        "\n",
        "\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  na=np.nan\n",
        "\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                 'A':[[11,28],[203,234],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,71],[104,138],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "\n",
        "  ####Changed this part####\n",
        "  rchoice = rangeChoices\n",
        "\n",
        "  ### extract plot subregions ###\n",
        "  # \"r\" stands for ramachandran\n",
        "  # regions: beta-strand, polyproline helix ii\n",
        "  #          beta-turn I, alpha-helix,\n",
        "  #          left handed helix (all phi > 0)\n",
        "  # !!! top and left corner are always >= or <=\n",
        "  #     unless they reach the bottom/right axis\n",
        "  #     (i.e. betaB, ppiiB, left)\n",
        "\n",
        "  #filter beta regions\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rbetaA'][0], np.array(phi) <= rchoice['rbetaA'][1])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rbetaA'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rbetaA'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['rbetaB'][0], np.array(phi) <= rchoice['rbetaB'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rbetaB'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rbetaB'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, mask2)\n",
        "\n",
        "  data_beta_ca = np.array(ca)[mask]\n",
        "  data_beta_cb = np.array(cb)[mask]\n",
        "  data_beta_c = np.array(c)[mask]\n",
        "  data_beta_n = np.array(n)[mask]\n",
        "\n",
        "  #filter ppii regions\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rppiiA'][0], np.array(phi) <= rchoice['rppiiA'][1])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rppiiA'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rppiiA'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['rppiiB'][0], np.array(phi) <= rchoice['rppiiB'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rppiiB'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rppiiB'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, mask2)\n",
        "\n",
        "  data_ppii_ca = np.array(ca)[mask]\n",
        "  data_ppii_cb = np.array(cb)[mask]\n",
        "  data_ppii_c = np.array(c)[mask]\n",
        "  data_ppii_n = np.array(n)[mask]\n",
        "\n",
        "  #filter ddgg\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['rdelta'][0], np.array(phi) <= rchoice['rdelta'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) >= rchoice['rdelta'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['rdelta'][3])\n",
        "\n",
        "  data_ddgg_ca = np.array(ca)[mask]\n",
        "  data_ddgg_cb = np.array(cb)[mask]\n",
        "  data_ddgg_c = np.array(c)[mask]\n",
        "  data_ddgg_n = np.array(n)[mask]\n",
        "\n",
        "  #filter turn\n",
        "  mask1 = np.logical_and(np.array(phi) >= rchoice['rturnI'][0], np.array(phi) < rchoice['ralpha'][0])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask1 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask2 = np.logical_and(np.array(phi) >= rchoice['ralpha'][1], np.array(phi) < rchoice['rturnI'][1])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask2 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask3 = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask3 = np.logical_and(mask1, np.array(psi) >= rchoice['rturnI'][2])\n",
        "  mask3 = np.logical_and(mask1, np.array(psi) <= rchoice['ralpha'][2])\n",
        "\n",
        "  mask4 = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask4 = np.logical_and(mask1, np.array(psi) > rchoice['ralpha'][3])\n",
        "  mask4 = np.logical_and(mask1, np.array(psi) <= rchoice['rturnI'][3])\n",
        "\n",
        "  mask = np.logical_or(mask1, np.logical_or(mask2, np.logical_or(mask3, mask4)))\n",
        "  data_turn_ca = np.array(ca)[mask]\n",
        "  data_turn_cb = np.array(cb)[mask]\n",
        "  data_turn_c = np.array(c)[mask]\n",
        "  data_turn_n = np.array(n)[mask]\n",
        "\n",
        "  #filter alph\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['ralpha'][0], np.array(phi) < rchoice['ralpha'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) > rchoice['ralpha'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['ralpha'][3])\n",
        "\n",
        "  data_alph_ca = np.array(ca)[mask]\n",
        "  data_alph_cb = np.array(cb)[mask]\n",
        "  data_alph_c = np.array(c)[mask]\n",
        "  data_alph_n = np.array(n)[mask]\n",
        "\n",
        "  #filter left\n",
        "  mask = np.logical_and(np.array(phi) >= rchoice['rlhelx'][0], np.array(phi) <= rchoice['rlhelx'][1])\n",
        "  mask = np.logical_and(mask1, np.array(psi) >= rchoice['rlhelx'][2])\n",
        "  mask = np.logical_and(mask1, np.array(psi) <= rchoice['rlhelx'][3])\n",
        "\n",
        "  data_left_ca = np.array(ca)[mask]\n",
        "  data_left_cb = np.array(cb)[mask]\n",
        "  data_left_c = np.array(c)[mask]\n",
        "  data_left_n = np.array(n)[mask]\n",
        "\n",
        "\n",
        "  # create dictionaries of data sets\n",
        "\n",
        "  cs_ca = ({'beta': data_beta_ca,\n",
        "            'ppii': data_ppii_ca,\n",
        "            'ddgg': data_ddgg_ca,\n",
        "            'left': data_left_ca,\n",
        "            'turn': data_turn_ca,\n",
        "            'alph': data_alph_ca,\n",
        "            })\n",
        "  cs_cb = ({'beta': data_beta_cb,\n",
        "            'ppii': data_ppii_cb,\n",
        "            'ddgg': data_ddgg_cb,\n",
        "            'left': data_left_cb,\n",
        "            'turn': data_turn_cb,\n",
        "            'alph': data_alph_cb,\n",
        "            })\n",
        "  cs_co = ({'beta': data_beta_c,\n",
        "            'ppii': data_ppii_c,\n",
        "            'ddgg': data_ddgg_c,\n",
        "            'left': data_left_c,\n",
        "            'turn': data_turn_c,\n",
        "            'alph': data_alph_c,\n",
        "            })\n",
        "\n",
        "  cs_all = {'ca':cs_ca,\n",
        "            'cb':cs_cb,\n",
        "            'c' :cs_co,\n",
        "            }\n",
        "\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  fig, axs = plt.subplots(1, 1, sharey=False, tight_layout=True,figsize=(10,10))\n",
        "\n",
        "  x_lims = np.array(aa_spec_ranges[aa1][0])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "  inputs = []\n",
        "  h_lists = []\n",
        "  h_list = []\n",
        "\n",
        "  for key in cs_ca:\n",
        "    H, bins, patches = axs.hist(cs_ca[key],bins=(x_edges),density=False,histtype='step')\n",
        "    for j in range(len(H)):\n",
        "      a = H[j]  # Maximum value\n",
        "      b = bins[j]  # Peak position\n",
        "      fwhm = 1.5  # Full width at half maximum\n",
        "\n",
        "      # Calculate the standard deviation from the FWHM\n",
        "      c = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "\n",
        "      x = np.linspace(b - 3 * c, b + 3 * c, 100)\n",
        "\n",
        "\n",
        "      # Calculate the y values for the curve using the Gaussian function\n",
        "      y = a * np.exp(-(x - b)**2 / (2 * c**2))\n",
        "\n",
        "      histogram, bins, patches = axs.hist(x,\n",
        "                        bins=x_edges,\n",
        "                        density=False,\n",
        "                        weights = y,\n",
        "                        histtype='step')\n",
        "      try:\n",
        "            if np.unique(histogram) != 0:\n",
        "              pass\n",
        "\n",
        "      except:\n",
        "        #print(histogram)\n",
        "\n",
        "        h_list.append(histogram)\n",
        "    h_lists = sum(h_list)\n",
        "    inputs.append(h_lists)\n",
        "\n",
        "  #print(inputs)\n",
        "  H_exp, bins, patches = axs.hist(ca_exp,bins=(x_edges),density=False,histtype='step')\n",
        "\n",
        "  target = (H_exp)\n",
        "  hists1 = (inputs[0])\n",
        "  hists2 = (inputs[1])\n",
        "  hists3 = (inputs[2])\n",
        "  hists4 = (inputs[3])\n",
        "  hists5 = (inputs[4])\n",
        "  hists6 = (inputs[5])\n",
        "  #print(np.shape(inputs),len(inputs[0]),len(target))\n",
        "  data = {'x1': list(hists1), 'x2': list(hists2), 'x3': list(hists3), 'x4':list(hists4), 'x5':hists5, 'x6':list(hists6), 'y': list(target) }\n",
        "  df = pd.DataFrame(data)\n",
        "  x = df[['x1','x2','x3','x4','x5','x6']]\n",
        "  y = df['y']\n",
        "\n",
        "  ###prevents plot from displaying\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "  model = sm.GLS(y,x)\n",
        "  results = model.fit()\n",
        "  return results.rsquared\n",
        "\n",
        "#new code starts here\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "topSep = -140.0 #range -180 : 0\n",
        "topH = 105.0 #range ~100 : 180\n",
        "\n",
        "middleH = 45.0 #range botH : topH\n",
        "\n",
        "botSep = -105.0 #range -180 : 0\n",
        "botH = -150.0 #range -180 : -100\"\"\"\n",
        "def returnDict1(topSep, topH, middleH, botSep, botH):\n",
        "  return {\n",
        "      #upper left\n",
        "      'rbetaA':(-180.0, topSep, topH, 180.0),\n",
        "      'rppiiA':( topSep,   0.0, topH, 180.0),\n",
        "\n",
        "      #Middle\n",
        "      'rdelta':(-180.0,   0.0,  middleH, 105.0),\n",
        "\n",
        "      #large middle box\n",
        "      'rturnI':(-180.0,   0.0, botH,  middleH), # turn is wider alpha\n",
        "\n",
        "      #smaller tiny box\n",
        "      'ralpha':(-40, -35, -100, -50), # alph is strictly alpha\n",
        "\n",
        "      #bottom left\n",
        "      'rbetaB':(-180.0, botSep,-180.0, botH),\n",
        "      'rppiiB':(botSep,    0.0,-180.0, botH),\n",
        "\n",
        "      'rlhelx':(   0.0, 180.0,-180.0, 180.0),\n",
        "  }\n",
        "\n",
        "def returnDict2(topSep, topH, middleH, botSep, botH, boxL1, boxL2, boxH1, boxH2):\n",
        "  return {\n",
        "      #upper left\n",
        "      'rbetaA':(-180.0, topSep, topH, 180.0),\n",
        "      'rppiiA':( topSep,   0.0, topH, 180.0),\n",
        "\n",
        "      #Middle\n",
        "      'rdelta':(-180.0,   0.0,  middleH, 105.0),\n",
        "\n",
        "      #large middle box\n",
        "      'rturnI':(-180.0,   0.0, botH,  middleH), # turn is wider alpha\n",
        "\n",
        "      #smaller tiny box\n",
        "      'ralpha':(boxL1, boxL2, boxH1, boxH2), # alph is strictly alpha\n",
        "\n",
        "      #bottom left\n",
        "      'rbetaB':(-180.0, botSep,-180.0, botH),\n",
        "      'rppiiB':(botSep,    0.0,-180.0, botH),\n",
        "\n",
        "      'rlhelx':(   0.0, 180.0,-180.0, 180.0),\n",
        "  }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwFOD-DoICBy"
      },
      "source": [
        "-120, 150, 0, -120, -90, -40, -40, -90, -45\n",
        "0.556: -125/145/0/-130/-100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOycWcs5WD_b"
      },
      "outputs": [],
      "source": [
        "print(returnDict2(-120, 150, 0, -120, -90, -40, -40, -90, -45))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddeSXTCSI5v4"
      },
      "outputs": [],
      "source": [
        "bestR = 0\n",
        "bestDict = None\n",
        "for topSep in range(-115, -99, 5):\n",
        "  print(f\"Outer: {topSep}: \\n\")\n",
        "  for topH in range(130, 146, 5):\n",
        "    for middleH in range(-20, -4, 5):\n",
        "      for botSep in range(-145, -124, 5):\n",
        "        for botH in range(-85, -59, 5):\n",
        "          #r = main(\"T_10K.out\", \"nanodisc.csv\", \"T\", returnDict(-180, 105, 45, -105, -150))\n",
        "          #print(r)\n",
        "          theDict = returnDict1(topSep, topH, middleH, botSep, botH)\n",
        "          r = main(\"T_10K.out\", \"nanodisc.csv\", \"T\", theDict)\n",
        "          if r > bestR:\n",
        "            print(f\"{str(round(r, 3))}: {topSep}/{topH}/{middleH}/{botSep}/{botH}\")\n",
        "            bestR = r\n",
        "            bestDict = theDict\n",
        "\n",
        "print(bestDict)\n",
        "print(f\"{bestDict['rbetaA'][1]}/{bestDict['rbetaA'][2]}/{bestDict['rturnI'][3]}/{bestDict['rbetaB'][1]}/{bestDict['rbetaB'][3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_DbckZSWPI1"
      },
      "outputs": [],
      "source": [
        "bestR = 0\n",
        "bestDict = None\n",
        "\n",
        "for boxL1 in range(-50, -29, 5):\n",
        "  print(f\"{boxL1}: \")\n",
        "  for boxL2 in range(boxL1+5, -24, 5):\n",
        "    for boxH1 in range(-100, -84, 5):\n",
        "      for boxH2 in range(-55, -39, 5):\n",
        "        theDict = returnDict2(-110, 140, -10, -130, -80, boxL1, boxL2, boxH1, boxH2)\n",
        "        r = main(\"T_10K.out\", \"nanodisc.csv\", \"T\", theDict)\n",
        "        if r > bestR:\n",
        "            print(f\"{str(round(r, 3))}: {boxL1}, {boxL2}, {boxH1}, {boxH2}\")\n",
        "            bestR = r\n",
        "            bestDict = theDict\n",
        "print(bestDict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jSZpnmu2nTS"
      },
      "source": [
        "random code for things:\n",
        "\n",
        "tempDict = {\n",
        "    #upper left\n",
        "    'rbetaA':(-180.0, -140.0, 105.0, 180.0),\n",
        "    'rppiiA':( -140.0,   0.0, 105.0, 180.0),\n",
        "\n",
        "    #Middle\n",
        "    'rdelta':(-180.0,   0.0,  45.0, 105.0),\n",
        "\n",
        "    #large middle box\n",
        "    'rturnI':(-180.0,   0.0,-150.0,  45.0), # turn is wider alpha\n",
        "    #smaller tiny box\n",
        "    'ralpha':( -90, -30, -60.0, -20.0), # alph is strictly alpha\n",
        "\n",
        "    #bottom left\n",
        "    'rbetaB':(-180.0,-105.0,-180.0,-150.0),\n",
        "    'rppiiB':(-105.0,   0.0,-180.0,-150.0),\n",
        "\n",
        "    'rlhelx':(   0.0, 180.0,-180.0, 180.0),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R4v-sC_JxR9"
      },
      "outputs": [],
      "source": [
        "print(\"Enter the file path, subplot number, and amino acid, separated by commas, or \\'Z\\' to quit: \")\n",
        "quit = False\n",
        "while not quit:\n",
        "  inputs = input()\n",
        "  if inputs.upper() == 'Z':\n",
        "    quit = True\n",
        "  else:\n",
        "    inputs = inputs.split(',')\n",
        "    input_file_path = inputs[0]\n",
        "    input_exp = inputs[1]\n",
        "    aa = inputs[2]\n",
        "    main(input_file_path, input_exp, aa)\n",
        "    print(\"Enter the file path for AA, file path for experimental data, subplot number, and amino acid, separated by commas, or \\'Z\\' to quit: \")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}