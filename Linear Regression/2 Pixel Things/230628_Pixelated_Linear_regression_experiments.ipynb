{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erictong0/FrederickLab2023/blob/main/Linear%20Regression/Pixel%20Things/230628_Pixelated_Linear_regression_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# irrelevant"
      ],
      "metadata": {
        "id": "eQF4MCDqkJQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbXwMbQrlDAY"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "!pip install bio --upgrade\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports for timing things\n",
        "!pip install line_profiler\n",
        "%load_ext line_profiler"
      ],
      "metadata": {
        "id": "ygSlwLXZOlhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as pltticker\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.patches import Rectangle\n",
        "import csv\n",
        "from matplotlib import colors\n",
        "import re\n",
        "import pandas as pd\n",
        "from numpy import savetxt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statistics import mean\n",
        "import statsmodels.api as sm\n",
        "from Bio.Data.IUPACData import protein_letters_1to3 as one2three\n",
        "import scipy.optimize as spo\n",
        "from pandas.core.internals.construction import ma\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "QdhKhzmOlO1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#works to load information in variables before the program\n",
        "\n",
        "fwhm = 2  # Full width at half maximum\n",
        "# Calculate the standard deviation from the FWHM\n",
        "c = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "\n",
        "def get_row_floats(data, row):\n",
        "  return list(map(lambda x: float(x[row]), data))\n",
        "\n",
        "xArray = []\n",
        "for i in range(68):\n",
        "  b = i / 4 + 54\n",
        "  xArray.append(np.linspace(b - 3 * c, b + 3 * c, 100))\n",
        "\n",
        "oData = []\n",
        "data = []\n",
        "with open(\"T_10K.out\", mode=\"r\") as infile: #open data file and read contents\n",
        "  reader = csv.reader(infile, delimiter=\"\\n\")\n",
        "  for row in reader:\n",
        "    if len(row) == 1:\n",
        "      data.append(re.split('\\t', row[0])[2:])\n",
        "    else:\n",
        "      data.append(row)\n",
        "\n",
        "tempData = []\n",
        "for i in range(6):\n",
        "  tempData.append(np.array(get_row_floats(data[1:], i)))\n",
        "\n",
        "oData.append(tempData)\n",
        "\n",
        "data = []\n",
        "tempData = []\n",
        "count = 0\n",
        "with open(\"spotlight 2022.csv\", mode=\"r\") as infile: #open data file and read contents\n",
        "  chunk_size = 1000\n",
        "  while True:\n",
        "      chunk = infile.readlines(chunk_size)\n",
        "      if not chunk:\n",
        "        break\n",
        "      for line in chunk:\n",
        "        reader = csv.reader(infile)\n",
        "        for row in reader:\n",
        "          count += 1\n",
        "          if len(row) == 1:\n",
        "            tempData.append(re.split(r',', row[0]))\n",
        "          else:\n",
        "            tempData.append(row)\n",
        "\n",
        "data.append(get_row_floats(tempData,0)[1:])\n",
        "data.append(get_row_floats(tempData,1)[1:])\n",
        "\n",
        "oData.append(data)\n",
        "\n",
        "DATAINPUT = oData"
      ],
      "metadata": {
        "id": "uAosrkRIlXzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import FALSE\n",
        "xScale = 10\n",
        "yScale = 10\n",
        "\n",
        "def main(inData, aa, rangeChoices):\n",
        "  aa1 = aa\n",
        "\n",
        "  phi = inData[0][0]\n",
        "  psi = inData[0][1]\n",
        "  ca = inData[0][2]\n",
        "  cb = inData[0][3]\n",
        "  c = inData[0][4]\n",
        "  n = inData[0][5]\n",
        "\n",
        "\n",
        "\n",
        "  ca_exp = inData[1][0] #def x as Ca shift\n",
        "  intensity = inData[1][1]\n",
        "\n",
        "\n",
        "  atom_key={\n",
        "            \"ca\":0,\n",
        "            \"cb\":1,\n",
        "            \"co\":2,\n",
        "            \"n\":3,\n",
        "          }\n",
        "\n",
        "  nonCys_nonGly_aas={\"A\", \"D\", \"E\", \"F\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "                    \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  nonCys_aas={\"A\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "              \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"Y\", \"W\"}\n",
        "\n",
        "  na=np.nan\n",
        "\n",
        "  aa_spec_ranges={ #ranges of interest for chemical shifts\n",
        "                  #aa1 Ca      Cb      C         N\n",
        "                  # Ca & Cb adjusted to 17ppm to match Fig5\n",
        "                 'A':[[11,28],[203,234],[170,184],[112,133]],\n",
        "                  'R':[[47,64],[22,39],[169,183],[112,133]],\n",
        "                  'N':[[44,61],[30,47],[168,182],[106,127]],\n",
        "                  'D':[[45,62],[33,50],[169,183],[109,130]],\n",
        "  #               'C':[[50,67],[22,39],[168,182],[105,126]],\n",
        "                  'Q':[[47,64],[22,39],[169,183],[108,129]],\n",
        "                  'E':[[49,66],[22,39],[169,183],[109,130]],\n",
        "                  'G':[[36,53],[203,234],[167,181],[ 98,119]],\n",
        "                  'H':[[49,66],[23,40],[168,182],[107,128]],\n",
        "                  'I':[[54,71],[31,48],[168,182],[109,130]],\n",
        "                  'L':[[45,62],[33,50],[170,184],[110,131]],\n",
        "                  'K':[[49,66],[26,43],[169,183],[109,130]],\n",
        "                  'M':[[47,64],[26,43],[169,183],[108,129]],\n",
        "                  'F':[[50,67],[31,48],[168,182],[107,128]],\n",
        "                  'P':[[57,74],[25,42],[170,184],[ na, na]],\n",
        "                  'S':[[50,67],[105,139],[55,72],[167,181],[104,125]],\n",
        "                  'T':[[54,70],[104,138],[60,77],[168,182],[102,123]],\n",
        "                  'W':[[48,65],[21,38],[169,183],[109,130]],\n",
        "                  'Y':[[50,67],[30,47],[168,182],[108,129]],\n",
        "                  'V':[[54,71],[25,42],[169,183],[108,129]],\n",
        "                  }\n",
        "\n",
        "  ####Changed this part####\n",
        "  rchoice = rangeChoices\n",
        "\n",
        "  ### extract plot subregions ###\n",
        "  # \"r\" stands for ramachandran\n",
        "  # regions: beta-strand, polyproline helix ii\n",
        "  #          beta-turn I, alpha-helix,\n",
        "  #          left handed helix (all phi > 0)\n",
        "  # !!! top and left corner are always >= or <=\n",
        "  #     unless they reach the bottom/right axis\n",
        "  #     (i.e. betaB, ppiiB, left)\n",
        "\n",
        "  #filter beta regions\n",
        "\n",
        "  def makeMask(a, b, c, d):\n",
        "    return np.logical_and(np.logical_and(phi >= a, phi <= b), np.logical_and(psi >= c, psi <= d))\n",
        "\n",
        "  masks = {}\n",
        "  datas = {}\n",
        "  cs_ca = {}\n",
        "  cs_cb = {}\n",
        "  cs_co = {}\n",
        "\n",
        "  for i in range(int(180/xScale)):\n",
        "    for j in range(int(360/yScale)):\n",
        "      name = f\"{chr(i+65)}{(j+1):02d}\"\n",
        "      mask = makeMask(i*xScale-180, (i+1)*xScale-180, 180-(j+1)*yScale, 180-j*yScale)\n",
        "      #print((i*10-180, i*10-170, 170-j*10, 180-j*10))\n",
        "      cs_ca[name] = ca[mask]\n",
        "      cs_cb[name] = cb[mask]\n",
        "      cs_co[name] = c[mask]\n",
        "\n",
        "  name = \"rturni\"\n",
        "  mask = makeMask(0, 180, -180, 180)\n",
        "  cs_ca[name] = ca[mask]\n",
        "  cs_cb[name] = cb[mask]\n",
        "  cs_co[name] = c[mask]\n",
        "  #cs_ca = list(cs_ca) ???\n",
        "\n",
        "  cs_all = {'ca':cs_ca,\n",
        "            'cb':cs_cb,\n",
        "            'c' :cs_co,\n",
        "            }\n",
        "\n",
        "  bin_width=0.25\n",
        "  mtick_spacing=5\n",
        "  #fig, axs = plt.subplots(1, 1, sharey=False, tight_layout=True,figsize=(10,10)) #35826579\n",
        "\n",
        "  x_lims = np.array(aa_spec_ranges[aa1][0])\n",
        "  y_lims = np.array(aa_spec_ranges[aa1][1])\n",
        "  x_edges = np.arange(x_lims[0],x_lims[1]+bin_width,bin_width) #create an array from one limit to the next using bin widths\n",
        "  y_edges=np.arange(y_lims[0],y_lims[1]+bin_width,bin_width)\n",
        "  hw=bin_width/2\n",
        "  center_bins_x=np.arange(x_lims[0]+hw,x_lims[1]+hw,bin_width)\n",
        "  center_bins_y=np.arange(y_lims[0]+hw,y_lims[1]+hw,bin_width)\n",
        "  inputs = []\n",
        "  h_lists = []\n",
        "  h_list = []\n",
        "  c = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
        "  for key in cs_ca:\n",
        "    H, bins = np.histogram(cs_ca[key],bins=(x_edges),density=False)\n",
        "    for j in range(len(H)):\n",
        "      a = H[j]  # Maximum value\n",
        "      b = bins[j]  # Peak position\n",
        "\n",
        "      x = xArray[round(b*4-216)]\n",
        "\n",
        "      # Calculate the y values for the curve using the Gaussian function\n",
        "      y = a * np.exp(-(x - b)**2 / (2 * c**2))\n",
        "      histogram, bins = np.histogram(x, bins=x_edges, density=False, weights = y)\n",
        "      h_list.append(histogram)\n",
        "    h_lists = sum(h_list)\n",
        "    inputs.append(h_lists)\n",
        "    #h_lists = []\n",
        "  H_exp, bins = np.histogram(ca_exp,bins=(x_edges),density=True, weights = intensity)\n",
        "  #plt.hist(ca_exp, bins = (x_edges), weights = intensity)\n",
        "  target = (H_exp)\n",
        "\n",
        "\n",
        "  #print(f\"{inputs}\\n{np.shape(inputs)}\")\n",
        "\n",
        "  tempArr = []\n",
        "  for element in inputs:\n",
        "    isSame = False\n",
        "    for element2 in tempArr:\n",
        "      if np.all(element == element2):\n",
        "        isSame = True\n",
        "    if isSame:\n",
        "      pass\n",
        "    else:\n",
        "      tempArr.append(element)\n",
        "  inputs = tempArr\n",
        "\n",
        "  #print(f\"{inputs}\\n{np.shape(inputs)}\")\n",
        "\n",
        "\n",
        "  data = {}\n",
        "  for i in range(len(inputs)):\n",
        "    data[f'x{i+1}'] = list(inputs[i])\n",
        "  data['y'] = list(target)\n",
        "\n",
        "  \"\"\"hists1 = (inputs[0])\n",
        "  hists2 = (inputs[1])\n",
        "  hists3 = (inputs[2])\n",
        "  hists4 = (inputs[3])\n",
        "  hists5 = (inputs[4])\n",
        "  hists6 = (inputs[5])\n",
        "  hists7 = (inputs[6])\n",
        "  #print(np.shape(inputs),len(inputs[0]),len(target))\n",
        "  data = {'x1': list(hists1), 'x2': list(hists2), 'x3': list(hists3), 'x4':list(hists4), 'x5': list(hists5), 'x6':list(hists6), 'x7':list(hists7), 'y': list(target)}\"\"\"\n",
        "  df = pd.DataFrame(data)\n",
        "  df.to_csv(\"test.csv\")\n",
        "  #print(df)\n",
        "  x = df.drop('y', axis=1)\n",
        "  #x = sm.add_constant(x)\n",
        "  y = df['y']\n",
        "  #print(df)\n",
        "\n",
        "  #lin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n",
        "              #positive=True, random_state=9999, selection='random')\n",
        "  #results = lin.fit(x,y)\n",
        "\n",
        "  #a[1]*x[1] + a[2]*x[2] + ... + a[i]*x[i] = y\n",
        "\n",
        "  spo.least_squares()\n",
        "\n",
        "  model = sm.OLS(y,x)\n",
        "  results = model.fit()\n",
        "\n",
        "\n",
        "  cs_ca_list = [cs_ca[element] for element in cs_ca.keys()]\n",
        "\n",
        "  #np.savetxt(\"pd dataframe nano\", df.values, fmt='%d')\n",
        "  return (results, cs_ca_list, H_exp)\n",
        "\n",
        "\n",
        "def func3P(dict):\n",
        "  r, s, e = main(DATAINPUT, \"T\", dict)\n",
        "  #print(r.summary())\n",
        "  return (r.summary(), s, e)\n",
        "\n",
        "resultString, cs_ca_list, H_exp = func3P({})"
      ],
      "metadata": {
        "id": "Mr287Mxvlir8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficientDict = {}\n",
        "#Fancy regex things to split the total result string into multiple arrays for each line, then further splits each one into the various columns\n",
        "tempArr = [re.sub(\" +\", \" \", element).split(\" \") for element in str(resultString).split(\"\\n\")[14:int(180*360/xScale/yScale) + 15]]\n",
        "#print(tempArr)\n",
        "r = re.sub(\" +\", \" \", str(resultString).split(\"\\n\")[2]).split(\" \")[5]\n",
        "print(tempArr)"
      ],
      "metadata": {
        "id": "BTdFb6-uRYIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultString)"
      ],
      "metadata": {
        "id": "2QL-eM1ZccFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempArr = tempArr[0:236]"
      ],
      "metadata": {
        "id": "IKE_8MM6cKSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([element[1] for element in tempArr])"
      ],
      "metadata": {
        "id": "Sj3jXxleemoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weightList = [element[1] for element in tempArr]\n",
        "histList = []\n",
        "#print(np.shape(weightList), np.shape(cs_ca_list))\n",
        "\n",
        "#plt.hist(cs_ca_list, bins = np.arange(54, 71, .25))\n",
        "for i in range(len(cs_ca_list)):\n",
        "  '''print(cs_ca_list[i])\n",
        "  print([weightList[i]] * len(cs_ca_list[i]))'''\n",
        "  if cs_ca_list[i] != []:\n",
        "    hist, bins1 = np.histogram(cs_ca_list[i], bins = np.arange( 54, 70, .25), weights = [float(weightList[i])] * len(cs_ca_list[i]))\n",
        "    histList.append(hist)\n",
        "print(np.shape(bins1), np.shape(histList))\n",
        "plt.hist(bins1[1:], bins = np.arange(54, 70, .25), weights = sum(histList))\n",
        "print(np.shape(H_exp))\n",
        "plt.hist(bins1, bins = np.arange(54,70,.25), weights = H_exp)\n",
        "print(np.shape(cs_ca_list))\n",
        "print(np.shape(weightList))\n",
        "\n",
        "#plt.hist(cs_ca_list, bins = (np.arange(54,71, .25)), weights = weightList)\n"
      ],
      "metadata": {
        "id": "TjeijoXjBU1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#makes a matplotlib rectangle object based on the coordinates of each corner.\n",
        "def makeRect(s, c):\n",
        "  return Rectangle((s[0], s[2]), s[1]-s[0], s[3]-s[2], color = c)\n",
        "\n",
        "#takes a dictionary and plots all of the various rectangles\n",
        "def visualizeRectangles(d, cs, r2):\n",
        "  norm = colors.Normalize(-2.7e+07, 2.7e+07)\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  for key in d.keys():\n",
        "    ax.add_patch(makeRect(d[key], cs[key]))\n",
        "\n",
        "  bound = 180\n",
        "  ax.set(xlim = (-1 * bound, bound), ylim = (-1*bound, bound))\n",
        "  plt.xlabel(\"φ/phi (deg)\")\n",
        "  plt.ylabel(\"Ψ/psi (deg)\")\n",
        "  plt.title(f\"Threonine Data: R²={round(r2, 3)}\")\n",
        "  fig.set_size_inches(6, 6)\n",
        "  fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cm.RdBu))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ITf5VvJi4gmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "otherVals = [element[1] for element in tempArr]\n",
        "print(otherVals)\n",
        "print(min(otherVals, key=float))\n",
        "print(max(otherVals, key = float))\n",
        "tempDict = {}\n",
        "tempColor = {}\n",
        "for i in range(100):\n",
        "  tempDict[i] = (i-180, i-179, -100, 100)\n",
        "  tempColor[i] = cm.RdBu(i/100)\n",
        "visualizeRectangles(tempDict, tempColor, -1)"
      ],
      "metadata": {
        "id": "Vv5wcTqf5Ox1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm = colors.Normalize(-2.7e+07, 2.7e+07)\n",
        "visDict = {}\n",
        "colorArray = {}\n",
        "valDict = {}\n",
        "for i in range(int(180/xScale)):\n",
        "  for j in range(int(360/yScale)):\n",
        "    visDict[f\"{chr(i+65)}{(j+1):02d}\"] = (i*xScale-180, (i+1)*xScale-180, 180-(j+1)*yScale, 180-j*yScale)\n",
        "    val = float(tempArr[int((i)*360/yScale + (j))][1])\n",
        "    #print(f\"{np.log(abs(val))} / {val}\")\n",
        "    valDict[f\"{chr(i+65)}{(j+1):02d}\"] = val\n",
        "    colorArray[f\"{chr(i+65)}{(j+1):02d}\"] = cm.RdBu(norm(val))\n",
        "\n",
        "visDict[\"rturni\"] = (0, 180, -180, 180)\n",
        "#print(visDict)\n",
        "colorArray[\"rturni\"] = cm.RdBu(float(tempArr[-1][1]))\n",
        "#print(valDict)\n",
        "visualizeRectangles(visDict, colorArray, float(r))\n",
        "\n",
        "print(colorArray)\n",
        "\n",
        "\n",
        "#otherVal = min(max(np.log(val*-1)*-1/4,0),1)\n",
        "#otherVal = min(max(np.log(float(tempArr[-1][1]))*-1/4,0),1)"
      ],
      "metadata": {
        "id": "zNKmUoCZcJlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmJp9Z775M9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xList = []\n",
        "yList = []\n",
        "for i in range(18):\n",
        "  for j in range(36):\n",
        "    xList.append(j)\n",
        "    yList.append(float(tempArr[(i)*36 + (j)][1]))\n",
        "    if abs(float(tempArr[(i)*36 + (j)][1])) > .2:\n",
        "      print(f\"{chr(i+65)}{(j+1):02d} / {abs(float(tempArr[(i)*18 + (j)][1]))}\")\n",
        "\n",
        "plt.scatter(xList, yList, s = .2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ag92OHOUXPME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relevant part\n"
      ],
      "metadata": {
        "id": "Ymf5hcIVjyX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Irrelevant part again"
      ],
      "metadata": {
        "id": "kGLLDCJmj5m2"
      }
    }
  ]
}